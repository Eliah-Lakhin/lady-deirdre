<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Lady Deirdre Guide</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="overview.html"><strong aria-hidden="true">2.</strong> Overview</a></li><li class="chapter-item expanded "><a href="lexis/lexis.html"><strong aria-hidden="true">3.</strong> Lexis</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="lexis/lexical-grammar.html"><strong aria-hidden="true">3.1.</strong> Lexical Grammar</a></li><li class="chapter-item expanded "><a href="lexis/scanning-process.html"><strong aria-hidden="true">3.2.</strong> Scanning Process</a></li><li class="chapter-item expanded "><a href="lexis/code-inspection.html"><strong aria-hidden="true">3.3.</strong> Code Inspection</a></li><li class="chapter-item expanded "><a href="lexis/token-references.html"><strong aria-hidden="true">3.4.</strong> Token References</a></li><li class="chapter-item expanded "><a href="lexis/site-references.html"><strong aria-hidden="true">3.5.</strong> Site References</a></li></ol></li><li class="chapter-item expanded "><a href="syntax/syntax.html"><strong aria-hidden="true">4.</strong> Syntax</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="syntax/syntax-grammar.html"><strong aria-hidden="true">4.1.</strong> Syntax Grammar</a></li><li class="chapter-item expanded "><a href="syntax/error-recovering.html"><strong aria-hidden="true">4.2.</strong> Error Recovering</a></li><li class="chapter-item expanded "><a href="syntax/debugging.html"><strong aria-hidden="true">4.3.</strong> Debugging</a></li><li class="chapter-item expanded "><a href="syntax/syntax-tree.html"><strong aria-hidden="true">4.4.</strong> Syntax Tree</a></li><li class="chapter-item expanded "><a href="syntax/node-references.html"><strong aria-hidden="true">4.5.</strong> Node References</a></li><li class="chapter-item expanded "><a href="syntax/tree-inspection.html"><strong aria-hidden="true">4.6.</strong> Tree Inspection</a></li><li class="chapter-item expanded "><a href="syntax/hand-written-parsers.html"><strong aria-hidden="true">4.7.</strong> Hand-Written Parsers</a></li><li class="chapter-item expanded "><a href="syntax/overriding-a-parser.html"><strong aria-hidden="true">4.8.</strong> Overriding a Parser</a></li><li class="chapter-item expanded "><a href="syntax/syntax-session.html"><strong aria-hidden="true">4.9.</strong> Syntax Session</a></li><li class="chapter-item expanded "><a href="syntax/pratts-algorithm.html"><strong aria-hidden="true">4.10.</strong> Pratt's Algorithm</a></li></ol></li><li class="chapter-item expanded "><a href="documents.html"><strong aria-hidden="true">5.</strong> Documents</a></li><li class="chapter-item expanded "><a href="semantics/semantics.html"><strong aria-hidden="true">6.</strong> Semantics</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="semantics/partition-into-scopes.html"><strong aria-hidden="true">6.1.</strong> Partition Into Scopes</a></li><li class="chapter-item expanded "><a href="semantics/grammar-setup.html"><strong aria-hidden="true">6.2.</strong> Grammar Setup</a></li><li class="chapter-item expanded "><a href="semantics/semantic-graph.html"><strong aria-hidden="true">6.3.</strong> Semantic Graph</a></li><li class="chapter-item expanded "><a href="semantics/incremental-computations.html"><strong aria-hidden="true">6.4.</strong> Incremental Computations</a></li><li class="chapter-item expanded "><a href="semantics/side-effects.html"><strong aria-hidden="true">6.5.</strong> Side Effects</a></li><li class="chapter-item expanded "><a href="semantics/scope-access.html"><strong aria-hidden="true">6.6.</strong> Scope Access</a></li><li class="chapter-item expanded "><a href="semantics/granularity.html"><strong aria-hidden="true">6.7.</strong> Granularity</a></li><li class="chapter-item expanded "><a href="semantics/the-analyzer.html"><strong aria-hidden="true">6.8.</strong> The Analyzer</a></li><li class="chapter-item expanded "><a href="semantics/tasks-management.html"><strong aria-hidden="true">6.9.</strong> Tasks Management</a></li><li class="chapter-item expanded "><a href="semantics/multi-file-analysis.html"><strong aria-hidden="true">6.10.</strong> Multi-File Analysis</a></li><li class="chapter-item expanded "><a href="semantics/language-server-design.html"><strong aria-hidden="true">6.11.</strong> Language Server Design</a></li><li class="chapter-item expanded "><a href="semantics/configuration-issues.html"><strong aria-hidden="true">6.12.</strong> Configuration Issues</a></li><li class="chapter-item expanded "><a href="semantics/code-diagnostics.html"><strong aria-hidden="true">6.13.</strong> Code Diagnostics</a></li><li class="chapter-item expanded "><a href="semantics/tree-index.html"><strong aria-hidden="true">6.14.</strong> Tree Index</a></li></ol></li><li class="chapter-item expanded "><a href="code-formatters/code-formatters.html"><strong aria-hidden="true">7.</strong> Code Formatters</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="code-formatters/pretty-printer.html"><strong aria-hidden="true">7.1.</strong> Pretty Printer</a></li></ol></li><li class="chapter-item expanded "><a href="snippets.html"><strong aria-hidden="true">8.</strong> Snippets</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Lady Deirdre Guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<img align="right" style="width: 160px" alt="Lady Deirdre Logo" src="https://raw.githubusercontent.com/Eliah-Lakhin/lady-deirdre/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/logo.png" />
<p>Lady Deirdre is a framework that helps you develop front-end code analysis
tools, such as code editor language extensions, programming language compilers
and interpreters, and even new code editors.</p>
<p>This guide will explain the main concepts of the API and walk you through the
steps of developing an analysis tool.</p>
<p>The book assumes that you already have some experience with the Rust programming
language and that you understand the core concepts of classical compilers:
lexical scanners, syntax parsers, regular expressions, context-free grammars,
etc.</p>
<p>If you have prior experience with code editor plugin development and
the <a href="https://microsoft.github.io/language-server-protocol/">LSP</a> protocol in
particular, it will certainly help you understand the material but is not
strictly required. The book will provide you with a brief overview of
the core concepts behind these tools.</p>
<h2 id="links"><a class="header" href="#links">Links</a></h2>
<ul>
<li><a href="https://github.com/Eliah-Lakhin/lady-deirdre">Source Code</a></li>
<li><a href="https://crates.io/crates/lady-deirdre">Main Crate</a></li>
<li><a href="https://docs.rs/lady-deirdre">API Documentation</a></li>
<li><a href="https://lady-deirdre.lakhin.com/">User Guide</a></li>
<li><a href="https://github.com/Eliah-Lakhin/lady-deirdre/tree/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples">Examples</a></li>
<li><a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md">License Agreement</a></li>
</ul>
<h2 id="copyright"><a class="header" href="#copyright">Copyright</a></h2>
<p>This work is proprietary software with source-available code.</p>
<p>To copy, use, distribute, or contribute to this work, you must agree to the
terms and conditions of the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md">General License Agreement</a>.</p>
<p>For an explanation of the licensing terms, see the
<a href="https://github.com/Eliah-Lakhin/lady-deirdre/tree/master/FAQ.md">F.A.Q.</a></p>
<p>Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин). All rights reserved.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<h2 id="the-domain"><a class="header" href="#the-domain">The Domain</a></h2>
<p>The program you are developing could function both as a programming language
compiler and as a code editor extension simultaneously. Lady Deirdre does not
strongly distinguish between these domains, so we will collectively refer to the
developing program as the <em>Compiler</em>.</p>
<p>The input data for the Compiler is a <em>compilation project</em>: a set of
semantically interconnected source code text files. We refer to each individual
file within a project as a compilation unit. A compilation unit could be a real
file stored on disk or have a more abstract source (e.g., transferred to the
Compiler by the code editor through the LSP communication channel).</p>
<p>The primary purpose of the front-end part of the Compiler is to determine if the
compilation project is well-formed (i.e., if there are syntax or semantic errors
in the compilation units) and to infer the semantic connections between the
source code objects (e.g., all call sites of a function in the source code).</p>
<p>The compilation project is subject to frequent changes, as the end user may
modify the source code of the units with every keystroke. The Compiler should
keep its internal representation in sync with these changes in real time.</p>
<p>Moreover, the compilation project is often not well-formed. While the end user
is writing the source code, it is usually in an incomplete state, with syntax
and semantic errors. Therefore, the Compiler should be resilient to these
errors, able to continuously synchronize the program's abstract representation
with the current state of the source code without halting at the first
encountered error.</p>
<p>The Compiler's best effort is to infer as much metadata as possible from the
current state of the source code to assist the end user in the code editor:
highlighting references between identifiers, providing code completion
suggestions, and enabling semantically meaningful navigation between text
symbols.</p>
<h2 id="the-core-concepts"><a class="header" href="#the-core-concepts">The Core Concepts</a></h2>
<p>Lady Deirdre separates the processes of lexical scanning, syntax parsing, and
semantic analysis.</p>
<p>Lexical and syntax analysis are performed on each compilation unit eagerly using
an incremental reparsing approach. With every end-user keystroke, the framework
patches the token stream and syntax tree relative to the changes.</p>
<p>As a result, incremental reparsing is usually a fast process even if the unit's
source code is large. This reparsing process does not alter the outer parts of
the syntax tree outside the typically small reparsing area, which is important
for the semantic analysis that relies on the states of the syntax tree.</p>
<p>Semantic analysis, in contrast, is a lazy, demand-driven process for the entire
compilation project. Lady Deirdre infers individual features of the semantic
model only when you explicitly request these features.</p>
<p>The model is described in terms of user-defined computable functions that
compute specific node's semantic metadata based on the compilation units' syntax
tree states and other computable function values. Together, these computable
functions form the <em>Semantic Graph</em>.</p>
<p>Lady Deirdre computes and incrementally updates this graph partially and
automatically when you request a feature, taking into account the changes in the
compilation units.</p>
<h3 id="compilation-units"><a class="header" href="#compilation-units">Compilation Units</a></h3>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html">Document</a>
object represents the source code text, token stream, and syntax tree of an
individual compilation unit.</p>
<p>Through the Document object, you can write to arbitrary fragments of the source
code and read its data at any time.</p>
<pre><code class="language-rust noplayground">let mut doc = Document::&lt;JsonNode&gt;::new_mutable(r#"{ "foo": 123 }"#);

 // Absolute zero-based index.
doc.write(3..6, "bar");

 // Line-column one-based index.
doc.write(Position::new(1, 4)..Position::new(1, 7), "baz");

assert_eq!(doc.substring(2..12), r#""baz": 123"#);

// Returns the root node of the syntax tree.
let _ = doc.root();

// Returns an iterator over the syntax errors.
let _ = doc.errors();

// Depth-first forth and back traverse of the syntax tree and its tokens.
doc.traverse_tree(&amp;mut my_visitor);

// Reads tokens within the token stream.
let _ = doc.chunks(..);</code></pre>
<p>The Document comes in two flavors: mutable and immutable. The mutable Document
supports incremental reparsing (as shown in the example above), while the
immutable Document does not support incremental reparsing but performs faster
when you load the source code text once.</p>
<p>There are no other API differences between these two document types, so you can
switch between the modes seamlessly. For example, if you want to switch off the
incremental compilation mode of your program, the program would function as a
pure one-pass compiler.</p>
<p>The Document is parameterized with the type that describes the lexical scanner
and syntax parser of the language, specifying the individual token type and the
syntax tree's node type.</p>
<h3 id="lexis"><a class="header" href="#lexis">Lexis</a></h3>
<p>First, you need to specify the type of the lexis. Typically, you can do this
using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/derive.Token.html">derive macro</a>
on your enum type, where the enum variants denote individual token types.
The token's lexical scanning rules are described in terms of regular expressions.</p>
<p>From the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_grammar/lexis.rs#L47">JSON example</a>:</p>
<pre><code class="language-rust noplayground">#[derive(Token)]
pub enum JsonToken {
    #[rule("true")]
    True,

    #[rule('{')]
    BraceOpen,

    #[rule('-'? ('0' | POSITIVE) ('.' DEC+)? (['e', 'E'] ['-', '+']? DEC+)?)]
    Number,
    
    //...
}</code></pre>
<p>The macro will generate a highly optimized lexical scanner based on the provided
regex rules.</p>
<p>In Lady Deirdre, the lexical scanning process is infallible. If there are source
code fragments that do not match the specified rules, these fragments will be
recognized as fallback "mismatch" tokens, which will generate syntax errors
during the syntax parsing stage.</p>
<h3 id="syntax"><a class="header" href="#syntax">Syntax</a></h3>
<p>The syntax grammar is described similarly using enum types and
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/derive.Node.html">derive macro</a>.</p>
<p>The node's parsing rules are described in terms of LL(1) grammars, but you can
also implement your own custom parsers for individual node types, allowing for
custom parse logic with unlimited recursion, including possibly left recursion.</p>
<p>Within the macro's parsing rules, you can capture the results of descending rule
applications and reference these results in the enum variant fields.</p>
<p>This system of references forms the node-to-child relationships between the
syntax tree nodes, which is useful for depth-first tree traversal. Additionally,
the parser establishes ascending node-to-parent relationships, allowing
traversal from nodes to the tree root. Lady Deirdre's incremental reparser
ensures both kinds of references are kept up to date.</p>
<p>From the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_grammar/syntax.rs#L52">JSON example</a>:</p>
<pre><code class="language-rust noplayground">#[derive(Node)]
#[token(JsonToken)] // Specifies a type of the Token.
pub enum JsonNode {
    #[rule($BracketOpen (items: ANY)*{$Comma} $BracketClose)]
    Array {
        #[parent] // Node-to-Parent relation.
        parent: NodeRef,
        #[child]// Node-to-Child relation.
        items: Vec&lt;NodeRef&gt;,
    },
    
    //...
}</code></pre>
<p>Most of the language syntax constructs, which can be easily expressed in terms
of LL(1) grammar rules, will be described this way. However, some complex
parsing rules, such as infix expressions, will be implemented manually using
hand-written recursive-descent parsers.</p>
<p>The syntax trees created by Lady Deirdre are, informally speaking, abstract
syntax trees where all trivial elements such as whitespaces and comments are
intentionally omitted. However, it is worth noting that you can also build a
full <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.ParseTree.html">ParseTree</a>
based on the same grammar, which has a different structure useful for
implementing code formatters.</p>
<p>The parser generated by the macro is an error-resistant parser capable of
recovering from syntax errors in the end user's code. It recovers from syntax
errors using standard "panic mode" algorithm and based on internal heuristics
statically inferred from the grammar. You have the option to explicitly
configure the recovery rules for the entire grammar and for individual parsing
rules for fine-tuning.</p>
<h3 id="ownership"><a class="header" href="#ownership">Ownership</a></h3>
<p>In Lady Deirdre, the source code tokens and syntax tree nodes are owned by the
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html">Document</a>.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.NodeRef.html">NodeRef</a>
and <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenRef.html">TokenRef</a>
objects are globally unique (composite) numerical indices that point to a
specific node or token inside the Document. They are unique in the sense that
whenever the incremental reparser removes a node or token, the corresponding
index object becomes obsolete forever, and the newly created node and token
instance always receives a unique index object that will never clash with the
index objects created previously by any Document.</p>
<p>Lady Deirdre uses NodeRefs, in particular, to establish parent-child relations
between syntax tree nodes.</p>
<p>This approach is convenient in that NodeRefs/TokenRefs, being just numerical
indices, are cheap and easy to Copy and are memory-allocation independent. You
can easily spread them across the program to address specific objects within a
particular document.</p>
<p>But the downside is that to dereference the addressed instance, you always
have to have access to the corresponding Document at the dereferencing point.</p>
<pre><code class="language-rust noplayground">let doc: Document&lt;JsonNode&gt;;
let token_ref: NodeRef;

let Some(token) = token_ref.deref(&amp;doc) else {
    panic!("TokenRef obsolete.");
}</code></pre>
<h3 id="traversing"><a class="header" href="#traversing">Traversing</a></h3>
<p>You can traverse the syntax tree either manually by dereferencing the NodeRef
index object and inspecting the enum variant fields, or generically, using the
NodeRef's grammar-independent functions. These functions include getting the
node's parent, children, or siblings, and addressing their children by string or
numerical keys.</p>
<pre><code class="language-rust noplayground">let doc: Document&lt;JsonNode&gt;;
let node_ref: NodeRef;

let foo_ref: NodeRef = node_ref
    .parent(&amp;doc)
    .last_child(&amp;doc)
    .get_child(&amp;doc, 3)
    .prev_sibling(&amp;doc)
    .get_child(&amp;doc, "foo");</code></pre>
<p>You can also traverse the entire syntax tree or a branch of the tree generically
using a visitor.</p>
<pre><code class="language-rust noplayground">let doc: Document&lt;JsonNode&gt;;
let branch_ref: NodeRef;

doc.traverse_subtree(&amp;branch_ref, &amp;mut MyVisitor);

struct MyVisitor;

impl Visitor for MyVisitor {
    fn visit_token(&amp;mut self, _token_ref: &amp;TokenRef) {}
    fn enter_node(&amp;mut self, _node_ref: &amp;NodeRef) -&gt; bool { true }
    fn leave_node(&amp;mut self, _node_ref: &amp;NodeRef) {}
}</code></pre>
<h3 id="semantics"><a class="header" href="#semantics">Semantics</a></h3>
<p>The semantic graph of the compilation project consists
of <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html">attributes</a>.</p>
<p>An attribute represents a value of arbitrary user-defined type, along with the
function that computes this value based on the values of other attributes read
within the function.</p>
<p>The value of the attribute can be of any type that implements Clone and Eq.</p>
<pre><code class="language-rust noplayground">#[derive(Clone, PartialEq, Eq)]
struct MyAttrValue {
    //...
}

impl Computable for MyAttrValue {
    type Node = MyNode;

    fn compute&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Self&gt; {
        // Computes and returns attribute's value using the `context` object.
    }
}</code></pre>
<p>The purpose of an attribute is to infer meaningful information related to a
particular node of the syntax tree. For instance, one attribute of the variable
declaration node could infer the type of that variable, while another attribute
might infer all variable uses across the code.</p>
<p>Attribute instances are owned by the syntax tree nodes. When defining the node,
attributes can be placed inside a special enum variant's <code>#[semantics]</code> field:</p>
<pre><code class="language-rust noplayground">#[derive(Node)]
struct MyNode {
    #[rule(&lt;parse rule&gt;)]
    SomeNodeVariant {
        //...
        #[semantics]
        semantics: Semantics&lt;Attr&lt;MyAttrValue&gt;&gt;,
    }
}</code></pre>
<p>If a node has more than one attribute, you should define a dedicated struct
where you would put these attributes. Then, you would use this struct as a
parameter of the <code>Semantics&lt;...&gt;</code> object.</p>
<p>Lady Deirdre computes attribute values only when you query them explicitly.</p>
<pre><code class="language-rust noplayground">let analysis_task; // You gets this object from the Analyzer (see next sections).
let node_ref: NodeRef;

let Some(MyNode::SomeNodeVariant { semantics, ... }) = node_ref.deref() else {...}

let (_, attribute_value) = semantics
    .get().unwrap()
    .my_attr.snapshot(&amp;analysis_task).unwrap();</code></pre>
<p>You can find a complete setup example of the syntax tree with semantics in the
<a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/syntax.rs">Chain Analysis</a>
example.</p>
<h3 id="concurrent-analysis"><a class="header" href="#concurrent-analysis">Concurrent Analysis</a></h3>
<p>Lady Deirdre is capable of computing the semantic graph of your compilation
project in a multi-threaded environment, handling concurrent requests to the
semantic attributes. Specifically, the language server can manage parallel
requests from the language client (code editor) in dedicated worker threads.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Analyzer.html">Analyzer</a>
object manages a collection of documents of the compilation project and the
semantic graph of the project.</p>
<p>It's assumed that this object will serve as the central synchronization point of
your compiler. You can interact with the Analyzer from multiple threads if
you're developing a multi-threaded compiler.</p>
<p>At any point in time, you can either edit the source code or query the semantic
graph. Due to this reason, the Analyzer doesn't allow direct access to its inner
content. Instead, it provides functions that grant access to specific
operations.</p>
<p>These functions return RAII-guard-like objects called "tasks" through which
necessary operations can be performed.</p>
<p>From the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/mod.rs#L84">Chain Analysis</a> example:</p>
<pre><code class="language-rust noplayground">let analyzer = Analyzer::&lt;ChainNode&gt;::new(AnalyzerConfig::default());

let doc_id;

{
    // A handle object through which we can signalize the task's worker
    // to cancel it's job. 
    let handle = TriggerHandle::new();

    // Requests Mutation task through which we can add new
    // or edit existing documents.
    let mut task = analyzer.mutate(&amp;handle, 1).unwrap();

    // Returns a unique identifier of the new document
    doc_id = task.add_mutable_doc(INPUT);
}

{
    let handle = TriggerHandle::new();
    
    // Requests semantic-analysis task.
    let task = analyzer.analyze(&amp;handle, 1).unwrap();

    // Here we can fetch the document by `doc_id`, traverse its nodes,
    // and query their semantics using the `task` object.
}</code></pre>
<p>The Analyzer's task system supports task priorities and a graceful shutdown
mechanism. The inner task manager of the Analyzer can signal the task's worker
thread to temporary interrupt its job based on the currently requested task
priorities.</p>
<p>It's important to note that the Analyzer itself is not a thread manager and does
not spawn any threads. Thread job management is not a goal of Lady Deirdre.</p>
<p>You can also use the Analyzer from a single main thread only. For example, you
can build your compiler to the wasm target and use the Analyzer's tasks
sequentially.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="lexis-1"><a class="header" href="#lexis-1">Lexis</a></h1>
<p>Lexical scanning is the initial stage of source code text analysis.</p>
<p>During this process, the scanner iterates through the characters of
a Unicode string, establishing token boundaries and associating each scanned
fragment, delimited by these boundaries, with a corresponding token instance.</p>
<p>The lexical scanner is a simple program that implements finite-state automata,
always looking at most one character ahead. Consequently, the scanner can
be restarted at any character of the text, which is particularly beneficial for
incremental rescanning. For instance, when an end user modifies a specific
portion of the source code text, the scanner restarts before the altered
fragment, eventually converging to the state of the tail of the text.</p>
<p>The resulting token stream serves as input for the syntax parser.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="lexical-grammar"><a class="header" href="#lexical-grammar">Lexical Grammar</a></h1>
<p>The lexical grammar is defined using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/derive.Token.html">Token derive macro</a>
on an arbitrary enum type, which represents the type of the token.</p>
<p>Each enum variant represents a token variant. To specify the scanning rule for
an individual variant, you annotate that variant with the <code>#[rule(...)]</code> macro
attribute and provide a regular expression to match the corresponding token.</p>
<p>The macro uses these expressions to build an optimized finite-state automaton,
from which it generates the scanning program..</p>
<p>From the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_grammar/lexis.rs#L47">JSON example</a>:</p>
<pre><code class="language-rust noplayground">use lady_deirdre::lexis::Token;

#[derive(Token, Clone, Copy, PartialEq, Eq)]
#[define(DEC = ['0'..'9'])]
#[define(HEX = DEC | ['A'..'F'])]
#[define(POSITIVE = ['1'..'9'] DEC*)]
#[define(ESCAPE = '\\' (
    | ['"', '\\', '/', 'b', 'f', 'n', 'r', 't']
    | ('u' HEX HEX HEX HEX)
))]
#[lookback(2)]
#[repr(u8)]
pub enum JsonToken {
    EOI = 0,

    Mismatch = 1,

    #[rule("true")]
    True,
    
    // ...

    #[rule('}')]
    BraceClose,
    
    // ...

    #[rule('"' (ESCAPE | ^['"', '\\'])* '"')]
    String,

    #[rule('-'? ('0' | POSITIVE) ('.' DEC+)? (['e', 'E'] ['-', '+']? DEC+)?)]
    Number,

    #[rule([' ', '\t', '\n', '\x0c', '\r']+)]
    Whitespace,
}</code></pre>
<p>The type must be Copy, Eq, and <code>#[repr(u8)]</code> enum type with variants without a
body.</p>
<p>The macro will implement
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.Token.html">Token</a>
trait on the applicable object, providing not only the scan function itself but
also additional metadata about the lexical grammar.</p>
<h2 id="special-tokens"><a class="header" href="#special-tokens">Special Tokens</a></h2>
<p>The <code>EOI</code> and <code>Mismatch</code> variants must be present in the enum<sup class="footnote-reference"><a href="#discriminant">1</a></sup>.</p>
<p>The EOI ("end-of-input") variant denotes the end of the source code. While
the scanner does not scan this token explicitly, it uses this variant in certain
API functions that return this token instance to indicate the end of the input
stream.</p>
<p>The Mismatch tokens are utilized by the scanning algorithm to represent source
code fragments that do not adhere to any lexical grammar rules. In essence, this
serves as a fallback token, indicating that the source code contains
unrecognized elements ("abracadabra").</p>
<p>In Lady Deirdre, scanning is, in principle, an infallible process. If the
scanning algorithm encounters a portion of the source code it cannot identify,
it emits the Mismatch token into the output stream. Depending on the parser,
this token may be recognized as a syntax parsing error.</p>
<div class="footnote-definition" id="discriminant"><sup class="footnote-definition-label">1</sup>
<p>They are determined by discriminant rather than their names.</p>
</div>
<h2 id="regular-expressions"><a class="header" href="#regular-expressions">Regular Expressions</a></h2>
<p>Inside the <code>#[rule(...)]</code> macro attribute, you specify the regular expression
that matches this token kind.</p>
<p>The expression language consists of a set of operators commonly found in typical
regular expression languages. These include character range match
operators (<code>['a'..'z', '0'..'9']</code>), repetition operators (<code>+</code>, <code>*</code>, <code>?</code>), and
character classes (<code>$upper</code>, <code>$alpha</code>, etc).</p>
<p>The macro supports predefined expressions (via <code>#[define(Name = Expr)]</code> as
shown in the example above) that could be inlined as-is an any other expression
by name, without recursion.</p>
<h2 id="grammar-ambiguity"><a class="header" href="#grammar-ambiguity">Grammar Ambiguity</a></h2>
<p>Every token scanning expression must match at least one character, as Lady
Deirdre does not allow empty tokens.</p>
<p>Additionally, the rules must be mutually exclusive. For instance, if you have a
scanning rule for identifiers <code>['a'..'z']+</code> and a dedicated keyword rule
<code>"package"</code>, both could potentially match the same text fragment "package".</p>
<p>To resolve this, you should prioritize the keyword variant over the identifier
by annotating it with a higher priority number <code>#[priority(1)]</code> (the default
priority being zero). Prioritizing the identifier instead would render the
keyword rule inapplicable, which is also considered an error.</p>
<p>The macro checks for these issues during compile time and yields corresponding
error messages when ambiguity errors are detected.</p>
<p>Lastly, in the above example, there is a <code>#[lookback(2)]</code> macro attribute that
specifies how many characters the rescanning algorithm should step back to
restart the incremental rescanning process. By default, this value is 1,
indicating that the rescanner must start the process from at least one character
back before the edited fragment. In the case of JSON, we need to ensure that
there are at least two characters available so that the rescanner can continue
rescanning of incomplete floating-point number literals ending with the dot
character.</p>
<h2 id="debugging"><a class="header" href="#debugging">Debugging</a></h2>
<p>You can debug the regular expressions by surrounding them with the <code>dump(...)</code>
operator: <code>'"' dump((ESCAPE | ^['"', '\'])*) '"'</code>. This will prompt the macro to
print the contents within the "dump" argument, displaying the state machine
transitions of this specific expression as interpreted by the macro. This
feature can be particularly useful when crafting complex lexical rules.</p>
<p>Additionally, you can annotate the enum type with the <code>#[dump]</code> macro attribute.
This will instruct the macro to print its generated output to the terminal,
allowing you to inspect the generated code. This is similar to using the
macro-expand tool, but the output will be properly formatted for readability.</p>
<h2 id="guidelines"><a class="header" href="#guidelines">Guidelines</a></h2>
<p>It is advisable to keep the lexical grammar as simple and granular as possible,
leaving the finer details to the syntax parsing stage.</p>
<p>In particular, I do not recommend scanning entire code comments and string
literals during lexical analysis. While in the example provided above, for the
sake of simplicity and demonstration, we scan string literals, in actual
applications, it would be preferable to scan just a <code>"</code> character as a single
token and define syntax parsing rules for strings in the syntax parser.</p>
<p>Informally speaking, you should only scan text portions between which you would
navigate when using the "ctrl ←" and "ctrl →" keyboard shortcuts in a code
editor.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="scanning-process"><a class="header" href="#scanning-process">Scanning Process</a></h1>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.Token.html">Token</a>
trait discussed in the previous chapter defines the scanning algorithm for
individual tokens, specific to the language grammar.</p>
<p>Actual scanning of source code and splitting it into tokens happens via another
trait, <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.LexisSession.html">LexisSession</a>.
This trait is independent of particular Token implementations; its purpose is
to run a scanning algorithm by feeding it the source code text characters as
input and registering the bounds of the tokens produced by that algorithm.</p>
<p>How these bounds are managed depends on the LexisSession implementation. Some
implementations store them in buffers or more complex internal collections;
others yield scanning results directly to the API user.</p>
<p>Unless you are implementing your own extension to the Lady Deirdre API, you do
not need to implement this low-level interface manually, and are encouraged to
use one of the provided solutions.</p>
<p>Specifically, Lady Deirdre offers three kinds of implementations:</p>
<ol>
<li><strong>Stateless Scanners</strong>. These scanners run the Token scanning algorithm on a
provided source code string and yield individual tokens with their metadata
to the API user via the Iterator interface. This is the simplest way to scan
source code (or a portion of it), leaving the scanning results entirely to the
API user. These scanners are also useful for quick-and-dirty debugging of a
Token implementation.</li>
<li><strong>Token Buffer</strong>. Scans the entire source code and stores the results in an
internal growable buffer. TokenBuffer provides random-access capabilities,
allowing inspection of tokens at any span of the source code. It also allows
appending additional text at the end of the buffer, enabling continuous
scanning, but it does not support finer-grained incremental edits (e.g.,
modifying or deleting arbitrary spans).</li>
<li><strong>Document</strong>. A full-featured stateful lexical scanner and syntax parser.
Provides random access to source code tokens and allows editing the source
text at any given point. We will discuss this object in more detail in the
next chapters.</li>
</ol>
<p>Each implementation has different performance characteristics and feature sets.
In most cases, when working only with the lexical layer of immutable text,
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenBuffer.html">TokenBuffer</a>
is the recommended choice: it balances performance and features well. If you
need to edit the text, consider using
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html">Document</a>
instead. Stateless scanners are most useful when you only need the generated
lexical stream and do not require the rest of the Lady Deirdre infrastructure.</p>
<h2 id="source-code-manager"><a class="header" href="#source-code-manager">Source Code Manager</a></h2>
<p>TokenBuffer and Document are both stateful objects: they store the state of
scanned tokens internally.</p>
<p>To allow inspection of this state — for example, iterating through tokens within
a specified source code span — these objects implement the
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.SourceCode.html">SourceCode</a>
trait. We will discuss this trait's API in more detail in the next chapter as
well.</p>
<p>We usually refer to these objects as <em>source code managers</em>. In summary, source
code managers typically implement two traits:</p>
<ol>
<li>The LexisSession trait, which provides a communication channel between the
source code text and the Token scanning algorithm.</li>
<li>The SourceCode trait, which gives end users access to the manager's scanned
tokens.</li>
</ol>
<p>To reiterate, both traits are low-level, and you typically do not need to
implement them manually unless you are creating a new type of source code
manager.</p>
<h2 id="stateless-scanners"><a class="header" href="#stateless-scanners">Stateless Scanners</a></h2>
<p>With the
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.Scannable.html">stateless scanners</a>,
you can run the scanning algorithm on arbitrary strings with minimal overhead.
This is useful for examining a Token implementation in action.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::lexis::Scannable;

let text = r#"{ "foo": ["bar", 1, false] }"#;

let mut token_vector = Vec::new();

// `Scannable::tokens()` creates a stateless lexical scanner that iterates
// through the scanned tokens.
for token in text.tokens::&lt;JsonToken&gt;() {
    token_vector.push(token);
}

println!("{:?}", token_vector);

// Or using just one line when debugging:

println!("{:?}", text.tokens::&lt;JsonToken&gt;());</code></pre>
<h2 id="token-buffer"><a class="header" href="#token-buffer">Token Buffer</a></h2>
<p><a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenBuffer.html">TokenBuffer</a>
persists scanned tokens, allows inspection of their metadata and the underlying
text at arbitrary points, and supports appending additional text to the end of
the source code.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::lexis::{TokenBuffer, SourceCode};

let mut buffer = TokenBuffer::&lt;JsonToken&gt;::from("[1, 2, 3");

assert_eq!(buffer.substring(..), "[1, 2, 3");

buffer.append(", 4, 5, 6]");

assert_eq!(buffer.substring(..), "[1, 2, 3, 4, 5, 6]");

// Prints all tokens in the token buffer to the terminal.
for chunk in buffer.chunks(..) {
    println!("{:?}", chunk.token);
}</code></pre>
<p>This type of source code manager is specifically designed for one-time and
continued lexical scanning and includes internal optimizations for these use
cases.</p>
<h2 id="documents-without-syntax"><a class="header" href="#documents-without-syntax">Documents Without Syntax</a></h2>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html">Document</a>
object provides full incremental reparsing capabilities and normally requires
specifying the syntax grammar, but you can use only its incremental scanning
features by using <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.VoidSyntax.html">VoidSyntax</a>.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{lexis::SourceCode, syntax::VoidSyntax, units::Document};

let mut doc = Document::&lt;VoidSyntax&lt;JsonToken&gt;&gt;::new_mutable(r#"{ "foo": 123 }"#);

doc.write(9..12, "456");

assert_eq!(doc.substring(..), r#"{ "foo": 456 }"#);</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="code-inspection"><a class="header" href="#code-inspection">Code Inspection</a></h1>
<h2 id="text-addressing"><a class="header" href="#text-addressing">Text Addressing</a></h2>
<p>In Lady Deirdre, the minimal unit for indexing the source code text is the
Unicode character.</p>
<p>A <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/type.Site.html">Site</a>
is a numeric type (an alias of <code>usize</code>) representing the absolute Unicode
character index in a string.</p>
<p><a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/type.SiteSpan.html">SiteSpan</a>
is an alias type of <code>Range&lt;Site&gt;</code> that denotes a fragment (or <em>span</em>) of the
source code.</p>
<p>Most API functions within the crate conveniently
accept <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.ToSite.html">impl ToSite</a>
or <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.ToSpan.html">impl ToSpan</a>
objects when users need to address specific source code
characters or spans of characters. These traits facilitate automatic conversion
between different representations of source code indices.</p>
<p>One example of a source code index type is
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.Position.html">Position</a>
object, which references code in terms of the line and column within the
line<sup class="footnote-reference"><a href="#position">1</a></sup>. It implements the <em>ToSite</em> trait.</p>
<p>For any type implementing the <em>ToSite</em> trait, <em>ToSpan</em> is automatically
implemented for all standard Rust range types with bound of this type.
For instance, both <em>Site</em> and <em>Position</em> types implement the <em>ToSite</em> trait,
making <code>10..20</code>, <code>10..=20</code>, and <code>10..</code>,
and <code>Position::new(10, 40)..Position::new(14, 2)</code> valid span types.</p>
<p>However, a particular span instance could be invalid; for instance, <code>20..10</code> is
invalid because its lower bound is greater than its upper bound.</p>
<p>Certain API functions in the crate (e.g.,
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html#method.write">Document::write</a>)
require that the specified span must be valid; otherwise, the function panics.
This behavior aligns with Rust's behavior when indexing arrays with invalid
ranges.</p>
<p>You can check the validity of a range upfront using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.ToSpan.html#tymethod.is_valid_span">ToSpan::is_valid_span</a>
function.</p>
<p>The RangeFull <code>..</code> object always represents the entire content and is always
valid.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::lexis::{Position, ToSpan, TokenBuffer};

let mut buf = TokenBuffer::&lt;JsonToken&gt;::from("foo\nbar\nbaz");

assert!((2..7).is_valid_span(&amp;buf));
assert!((2..).is_valid_span(&amp;buf));
assert!((..).is_valid_span(&amp;buf));
assert!(!(7..2).is_valid_span(&amp;buf));
assert!((Position::new(1, 2)..Position::new(3, 1)).is_valid_span(&amp;buf));</code></pre>
<div class="footnote-definition" id="position"><sup class="footnote-definition-label">1</sup>
<p>Please note that the line and column numbers in
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.Position.html">Position</a>
object are one-based: 1 denotes the first line, 2 denotes the second line, and
so forth.</p>
</div>
<h2 id="text-inspection"><a class="header" href="#text-inspection">Text Inspection</a></h2>
<p>The
following <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.SourceCode.html">SourceCode</a>'
s functions enable you to query various metadata of the compilation unit's text.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::lexis::{SourceCode, TokenBuffer};

let mut buf = TokenBuffer::&lt;JsonToken&gt;::from("foo, bar, baz");

// The `substring` function returns a `Cow&lt;str&gt;` representing the substring
// within the specified span.
// The underlying implementation attempts to return a borrowed string whenever
// possible.
assert_eq!(buf.substring(2..7), "o, ba");

// Iterates through the Unicode characters in the span.
for ch in buf.chars(2..7) {
    println!("{ch}");
}

// A total number of Unicode characters.
assert_eq!(buf.length(), 13);

// Returns true if the code is empty (contains no text or tokens).
assert!(!buf.is_empty());

// A total number of lines (delimited by `\n`).
assert_eq!(buf.lines().lines_count(), 1);</code></pre>
<p>From <code>buf.lines()</code>, you receive
a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.LineIndex.html">LineIndex</a>
object that provides additional functions for querying metadata about the source
code lines. For example, you can fetch the length of a particular line using
this object.</p>
<h2 id="tokens-iteration"><a class="header" href="#tokens-iteration">Tokens Iteration</a></h2>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.SourceCode.html#tymethod.cursor">SourceCode::cursor</a>
and its simplified
version <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.SourceCode.html#method.chunks">chunks</a>
allow you to iterate through the tokens of the source code.</p>
<p>Both functions accept a span of the source code text and yield tokens that
"touch" the specified span. Touching means that the token's string is fully
covered by, intersects with, or at least contacts the span within its bounds.</p>
<p>For example, if the text "FooBarBazWaz" consists of the tokens "Foo", "Bar",
"Baz", and "Waz", the span <code>3..7</code> would contact the "Foo" token (3 is the end of
the token's span), fully cover the "Bar" token, and intersect with the "Baz"
token (by the "B" character). However, the "Waz" token is outside of this span
and will not be yielded.</p>
<p>In other words, these functions attempt to yield the widest set of tokens that
are in any way related to the specified span.</p>
<p>The <em>chunks</em> function simply returns a standard iterator over the token
metadata. Each
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.Chunk.html">Chunk</a>
object contains the token instance, a reference to its string, the absolute Site
of the beginning of the token, and the substring length in Unicode
characters<sup class="footnote-reference"><a href="#chunk">2</a></sup>.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::lexis::{Chunk, SourceCode, TokenBuffer};

let buf = TokenBuffer::&lt;JsonToken&gt;::from("123 true null");

for Chunk {
    token,
    string,
    site,
    length,
} in buf.chunks(..)
{
    println!("---");
    println!("Token: {token:?}");
    println!("String: {string:?}");
    println!("Site: {site}");
    println!("Length: {length}");
}</code></pre>
<p>The <em>cursor</em> function returns a more
complex <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.TokenCursor.html">TokenCursor</a>
object that implements a cursor-like API with built-in lookahead capabilities
and manual control over the iteration process. This object is particularly
useful for syntax parsing and will be discussed in more detail in the subsequent
chapters of this guide.</p>
<p>To give you a brief overview of the token cursor, the above code could be
rewritten with the token cursor as follows:</p>
<pre><code class="language-rust noplayground">use lady_deirdre::lexis::{SourceCode, TokenBuffer, TokenCursor};

let buf = TokenBuffer::&lt;JsonToken&gt;::from("123 true null");

let mut cursor = buf.cursor(..);

loop {
    // 0 means zero lookahead -- we are looking at the point of where the cursor
    // is currently pointing.
    let token = cursor.token(0);

    // If the cursor reached the end of input, we are breaking the loop.
    if token == JsonToken::EOI {
        break;
    }

    println!("---");
    println!("Token: {:?}", cursor.token(0));
    println!("String: {:?}", cursor.string(0));
    println!("Site: {:?}", cursor.site(0));
    println!("Length: {:?}", cursor.length(0));

    // Manually moves token cursor to the next token.
    cursor.advance();
}</code></pre>
<div class="footnote-definition" id="chunk"><sup class="footnote-definition-label">2</sup>
<p>Note that the <em>Chunk</em> object represents a valid span and implements
the <em>ToSpan</em> trait.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="token-references"><a class="header" href="#token-references">Token References</a></h1>
<p>Lexical structures (tokens) are owned by the source code managers, such as
TokenBuffers and Documents, which implement the SourceCode trait through which
you can access the tokens.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenRef.html">TokenRef</a>
is a convenient interface containing a composite numeric index that uniquely
addresses a token in the source code. As a numeric index, it is a Copy and
lifetime-independent object that you can freely use throughout your program.
However, TokenRef could potentially represent an invalid or obsolete pointer.
Therefore, most TokenRef functions require passing a reference to the source
code manager and may return None if the corresponding token does not exist in
the manager.</p>
<p>For example,
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenRef.html#method.deref">TokenRef::deref</a>
function "dereferences" the token and returns Some if the token exists in the
specified compilation unit, or None otherwise.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::lexis::{SourceCode, TokenBuffer, TokenCursor, TokenRef};

let mut buf_1 = TokenBuffer::&lt;JsonToken&gt;::from("123 true null");
let buf_2 = TokenBuffer::&lt;JsonToken&gt;::new();

// Get the reference to the first token in the TokenBuffer.
let first_token: TokenRef = buf_1.cursor(..).token_ref(0);

// Gets an instance of the Token instance.
assert_eq!(first_token.deref(&amp;buf_1), Some(JsonToken::Number));

// Gets a string fragment covered by this token.
assert_eq!(first_token.string(&amp;buf_1), Some("123"));

// Checks validity of the TokenRef for specified compilation unit.
assert!(first_token.is_valid_ref(&amp;buf_1));

// However, this token reference is not valid for buf_2.
assert_eq!(first_token.deref(&amp;buf_2), None);

// Removing all tokens from the TokenBuffer.
buf_1.clear();

// As such, the reference is no longer valid for the buf_1 as well.
assert_eq!(first_token.deref(&amp;buf_1), None);</code></pre>
<p>The source of TokenRef objects could be token cursors (as in the example above),
but typically, you will obtain them by inspecting nodes of the syntax trees.</p>
<h2 id="tokenref-lifetime"><a class="header" href="#tokenref-lifetime">TokenRef Lifetime</a></h2>
<p>The TokenRef reference is unique in the following ways:</p>
<ol>
<li>It uniquely addresses a particular compilation unit.</li>
<li>It uniquely addresses a particular token within this unit.</li>
</ol>
<p>If the incremental source code manager (such
as <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html">Document</a>)
rescans the source code fragment to which the token belongs, its TokenRef
reference would effectively become obsolete. Every new token in the Document
would receive a new unique instance of the TokenRef object.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenRef.html#method.is_valid_ref">TokenRef::is_valid_ref</a>
function tests the validity of the reference for a specified compilation unit.</p>
<h2 id="nil-tokenref"><a class="header" href="#nil-tokenref">Nil TokenRef</a></h2>
<p>TokenRefs have one special "nil" value. Nil token references are special
references that intentionally do not address any tokens within any compilation
unit.</p>
<p>These TokenRefs are created with
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenRef.html#method.nil">TokenRef::nil</a>
function and can be tested using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.PolyRef.html#tymethod.is_nil">is_nil</a>
function. The <em>is_nil</em> function returns true only for token references created
this way; otherwise, it returns false, even if the TokenRef is obsolete.</p>
<p>Nil TokenRefs are useful to mimic the <code>Option::None</code> discriminant, so you don't
have to wrap a TokenRef type in an Option.</p>
<p>The crate API never wraps TokenRef in an <code>Option&lt;TokenRef&gt;</code> type. Instead, if
the value cannot be computed, the API uses a nil TokenRef.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="site-references"><a class="header" href="#site-references">Site References</a></h1>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/type.Site.html">Site</a>
index, which represents the absolute offset of a Unicode character in the source
code text, cannot reliably address a token's absolute offset after source code
edits. This is because the token could be shifted left or right, or it could
disappear during incremental rescanning, depending on the bounds of the edit.</p>
<p>In contrast,
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenRef.html#method.site">TokenRef::site</a>
returns the absolute offset of the beginning of the token's string fragment at
the time of the call. In other words, this function returns an updated absolute
offset of the token after an edit operation, provided the incremental rescanner
did not remove the token during rescanning.</p>
<p>This allows for addressing a token's character bounds relative to changes in the
source code.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.SiteRef.html">SiteRef</a>
helper object (backed by the TokenRef under the hood) addresses token bounds.
Specifically, this object addresses either the beginning of the token or the end
of the source code.</p>
<p><a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.ToSite.html">ToSite</a>
implements the ToSite trait, so it can be used as a valid bound of a range span.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    lexis::{SiteRef, SourceCode, TokenCursor},
    syntax::VoidSyntax,
    units::Document,
};

let mut doc = Document::&lt;VoidSyntax&lt;JsonToken&gt;&gt;::new_mutable("foo [bar] baz");

let brackets_start: SiteRef = doc.cursor(..).site_ref(2);
let brackets_end: SiteRef = doc.cursor(..).site_ref(5);

assert_eq!(doc.substring(brackets_start..brackets_end), "[bar]");

// Rewriting "bar" to "12345".
doc.write(5..8, "12345");

assert_eq!(doc.substring(brackets_start..brackets_end), "[12345]");</code></pre>
<p>Similar to TokenRef, the SiteRef interface has a
special <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.SiteRef.html#method.nil">nil</a>
value and
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.SiteRef.html#method.is_nil">is_nil</a>
test function.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="syntax-1"><a class="header" href="#syntax-1">Syntax</a></h1>
<p>The next stage of source code analysis after lexical scanning is syntax parsing.</p>
<p>The input for syntax parser is stream of tokens produced during the
lexical scanning or incremental rescanning stage.</p>
<p>Syntax parsing, and especially incremental reparsing, is a more complex process
that includes error recovery and other features. However, you will find many
similarities between the lexical scanning and syntax parsing APIs of Lady
Deirdre.</p>
<p>The output of the syntax parser is a syntax tree, which is used in the semantic
analysis stage.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="syntax-grammar"><a class="header" href="#syntax-grammar">Syntax Grammar</a></h1>
<p>You define the syntax grammar using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/derive.Node.html">Node derive macro</a>
on an arbitrary enum type that serves as the type for the syntax tree nodes.</p>
<p>Unlike the token enum, the node enum variants are required to have bodies with
fields. These fields allow the parser to store parent-child relationships
between nodes.</p>
<p>The node's parser is described in terms
of <a href="https://en.wikipedia.org/wiki/LL_parser">LL(1)</a> grammars using
the <code>#[rule(...)]</code> macro attributes, which denote individual variant grammar
rules.</p>
<p>Within these regex-like parse expressions, you can refer to other variants,
establishing recursive descent parsing between the parse procedures.</p>
<p>Additionally, you can name any subexpression with the <code>field:</code> prefix inside the
expression. This syntax enforces the generated parser to capture the result of
the subexpression matching (whether it be a token or a syntax tree node) and
place the matching result into the variant's field with the same name.</p>
<p>This process is called <em>capturing</em>, and it allows the parser to establish the
node-to-children descending relationships between nodes.</p>
<p>The opposite ascending node-to-parent relationships are established
automatically if you declare a variant field with the <code>#[parent]</code> macro
attribute.</p>
<p>From the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_grammar/syntax.rs">JSON example</a>:</p>
<pre><code class="language-rust noplayground">
#[derive(Node)]
#[token(JsonToken)]
#[trivia($Whitespace)]
#[define(ANY = Object | Array | True | False | String | Number | Null)]
#[recovery(
    $BraceClose,
    $BracketClose,
    [$BraceOpen..$BraceClose],
    [$BracketOpen..$BracketClose],
)]
pub enum JsonNode {
    #[root]
    #[rule(object: Object)]
    Root {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        object: NodeRef,
    },

    #[rule(start: $BraceOpen (entries: Entry)*{$Comma} end: $BraceClose)]
    Object {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        start: TokenRef,
        #[child]
        entries: Vec&lt;NodeRef&gt;,
        #[child]
        end: TokenRef,
    },

    #[rule(key: String $Colon value: ANY)]
    Entry {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        key: NodeRef,
        #[child]
        value: NodeRef,
    },
    
    // ...

    #[rule(value: $String)]
    #[secondary]
    String {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        value: TokenRef,
    },
}</code></pre>
<p>The Node macro generates an optimized and error-resistant syntax parser based on
the provided grammar rules. The macro allows you to replace individual
node-generated parsers with hand-written parsers, where you can implement custom
recursive-descent logic with potentially unlimited lookahead and left recursion.
Hand-written parsers will be discussed in more detail in the next chapters of
this guide.</p>
<h2 id="macro-api"><a class="header" href="#macro-api">Macro API</a></h2>
<p>In this chapter, I will intentionally omit some details, referring you to
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/derive.Node.html">macro documentation</a>
for a more verbose description of the available features, and to
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_grammar/syntax.rs">JSON example</a>
as an example of a node implementation that utilizes most of the macro's
capabilities.</p>
<p>Some general points to note about the macro API are:</p>
<ol>
<li>The <code>#[token(JsonToken)]</code> macro attribute specifies the type of the token.
This attribute is required and denotes the alphabet of the parsing input.</li>
<li>The <code>#[trivia($Whitespace)]</code> macro attribute describes elements that you want
to omit automatically in the variant parsers between matching tokens. Trivia
is a normal parsing expression that will be repeated zero or more times
between each token. Typically, this expression enumerates whitespace tokens
and refers to the comment variants of the grammar. The trivia expression can
be overridden for each parsable variant (e.g., comments and string parsers
might have different trivia expressions).</li>
<li>There is exactly one enum variant annotated with the <code>#[root]</code> macro
attribute. This variant denotes the syntax tree root and serves as the entry
point of the grammar.</li>
<li>A variant field annotated with the <code>#[node]</code> attribute is a reference to the
current node<sup class="footnote-reference"><a href="#noderef">1</a></sup>.</li>
<li>A variant field with the <code>#[parent]</code> attribute is a reference to the parent
node of the current node. This field establishes a node-to-parent relation
and will be automatically updated by the incremental reparser.</li>
<li>A variant field with the <code>#[child]</code> attribute establishes a node-to-child
relation. The name of the field must match one of the capturing operator
keys, and the type must correspond to the capturing type (node or token) and
the capturing repetition.</li>
</ol>
<div class="footnote-definition" id="noderef"><sup class="footnote-definition-label">1</sup>
<p>NodeRef references are similar to TokenRef composite-index
references, as they point to particular syntax tree instances of the compilation
unit. We will discuss them in more detail in the next chapters as well.</p>
</div>
<h2 id="incremental-reparsing"><a class="header" href="#incremental-reparsing">Incremental Reparsing</a></h2>
<p>The parser generated by the macro will be suitable for incremental reparsing.</p>
<p>By default, all node variants are subject to eager caching during incremental
reparsing. These variant nodes are called <em>Primary</em>.</p>
<p>If you annotate a variant with the <code>#[secondary]</code> macro attribute, you inform
the macro that this node is <em>Secondary</em>, and it should not be cached.</p>
<h2 id="rule-expressions"><a class="header" href="#rule-expressions">Rule Expressions</a></h2>
<p>The expression syntax of the <code>#[rule(...)]</code> macro attribute is similar to the
regular expression syntax of the Token macro, except that inside the parse
expression, we match tokens (prefixed with a dollar sign: <code>$Colon</code>) and nodes
(without a dollar sign: <code>Object</code>) instead of Unicode characters.</p>
<p>Since the LL(1) parser is a recursive-descent parser that looks at most one
token ahead to make a decision in the choice operator (<code>A | B</code>), you should
consider the leftmost set<sup class="footnote-reference"><a href="#leftmost">2</a></sup> of the descending rules.</p>
<p>For example, the expression <code>A | B</code> would be ambiguous if both A and B variant
rules could start matching with the same token. Similarly, the
expression <code>A | $Foo</code> would be ambiguous if A could start with the <code>$Foo</code> token.</p>
<p>All variant rules except the <code>#[root]</code> variant and the trivia expressions must
parse at least one token. The Root variant is allowed to parse potentially empty
token streams.</p>
<p>The macro will check these and other requirements and yield descriptive error
messages if one of the requirements is violated.</p>
<p>Similar to the Token's regexes, you can use the <code>dump(...)</code> operator for
debugging purposes, which prints the state-machine transitions, captures, and
the leftmost set of the surrounding parse expression.</p>
<div class="footnote-definition" id="leftmost"><sup class="footnote-definition-label">2</sup>
<p>The set of tokens from which the parse rule starts matching
directly or indirectly by descending into other rules is called the "leftmost
set".</p>
</div>
<h2 id="capturing"><a class="header" href="#capturing">Capturing</a></h2>
<p>The expression operator <code>start: $BraceOpen</code> means that the parser matches the
token "BraceOpen" and puts its TokenRef reference into the "start" field of the
variant's body.</p>
<p>The operator can capture either a node or a token. If there is something else on
the right-hand side, the capture operator will be spread to the inner operands.
For example, <code>foo: (Bar | Baz*)</code> means the same as <code>(foo: Bar) | (foo: Baz)*</code>.</p>
<p>The type of the corresponding field depends on what the operator captures (node
or token) and how many times. If the operator could be applied no more than
once, the field type would be NodeRef or TokenRef, respectively. If the operator
could be applied more than once, the type would be a Vec of NodeRef or TokenRef.</p>
<p>Examples:</p>
<ul>
<li>In <code>foo: Bar</code>, the "foo" field would have the type NodeRef.</li>
<li>In <code>foo: $Bar</code>, the "foo" field would have the type TokenRef.</li>
<li>In <code>foo: Bar &amp; foo: Baz</code>, the "foo" field would have the type Vec<NodeRef>.</li>
<li>In <code>foo: Bar*</code>, the "foo" field would also have the type Vec<NodeRef>.</li>
<li>In <code>foo: $Bar?</code>, the "foo" field would have the type TokenRef because "Bar"
can be matched no more than one time. If the parser never matches "Bar", the
"foo" field receives the
value <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenRef.html#method.nil">TokenRef::nil</a>.</li>
</ul>
<h2 id="guidelines-1"><a class="header" href="#guidelines-1">Guidelines</a></h2>
<ol>
<li>
<p><strong>Keep the syntax grammar simple</strong>.</p>
<p>The purpose of the syntax tree is to express the general nesting structure of
the source code to assist the further semantic analysis stage. If your
language grammar contains rules that require higher-level lookaheads or
context-dependent parsing, it might be better to parse a more simplified
subset of this syntax at the syntax parse stage, leaving the rest of the
analysis to the semantic stage.</p>
</li>
<li>
<p><strong>Always capture the start and end bounds of the node</strong>.</p>
<p>If your parse rules would capture the start and end tokens either directly or
indirectly by capturing the starting and ending nodes of this node, these
captures would help Lady Deirdre properly understand the starting and ending
sites of the node. This is especially important for functions such as
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.NodeRef.html#method.span">NodeRef::span</a>
function.</p>
<p>In particular, for this reason, in
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_grammar/syntax.rs#L96">JSON object and array rules</a>,
we capture start and end tokens even though they are meaningless in terms of
syntax tree traversing.</p>
</li>
<li>
<p><strong>Annotate the captured fields with the <code>#[child]</code> attribute</strong>.</p>
<p>By annotating the captured field with this attribute, you make it clear that
the corresponding field should be treated as a node's child, even if this
child is a token.</p>
<p>For instance,
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxTree.html#method.traverse_tree">traverse_tree</a>
function relies on this metadata when performing the syntax tree depth-first
traversal.</p>
</li>
<li>
<p><strong>Keep the <code>#[child]</code> fields in order</strong>.</p>
<p>For the same reasons, the captured fields should appear in the variant's body
in the same order as they appear in the parse expressions. For example, if
you have a <code>#[rule(foo: $Foo &amp; bar: Bar* &amp; baz: $Baz)]</code> rule, the variant
fields should come in this order: "foo", "bar", and "baz".</p>
</li>
<li>
<p><strong>Don't capture semantically meaningless inner tokens</strong>.</p>
<p>Capturing a comma token in a comma-separated list, for example, is likely
unnecessary because you wouldn't rely on the list separators when analyzing
the list.</p>
<p>Note that for source code formatting purposes, you would use a dedicated API
where all tokens are intentionally included in the parse tree regardless of
their omission in the syntax tree.</p>
</li>
<li>
<p><strong>Prefer wrapping semantically meaningful tokens into dedicated nodes</strong>.</p>
<p>When you encounter an intermediate token in the rule's expression that
potentially addresses semantic metadata (e.g., a variable identifier
in <code>let x</code>), you always have a choice: either capture it as is or introduce a
dedicated node (e.g., "Identifier") that captures the token separately, and
then capture the introduced node in the rule.</p>
<p>For semantic analysis purposes, it would be more convenient to always work
with node captures, so you should prefer wrapping.</p>
<p>For example, in
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_grammar/syntax.rs#L83">JSON object entry rule</a>,
we capture the entry's key as a node-wrapper (String node) rather than as a
token for this reason.</p>
</li>
<li>
<p><strong>Make the leaf nodes the Secondary nodes</strong>.</p>
<p>By default, all nodes of the syntax tree are subject to eager caching. In
practice, the incremental reparser probably performs better if you limit the
cache to the structurally complex nodes only and annotate the rest of the
node variants with the <code>#[secondary]</code> attribute.</p>
<p>In the JSON example syntax, Root, Object, Entry, and Array are the primary
nodes and could be cached during incremental reparsing. However, the leaf
nodes such as String, Number, and others are secondary nodes. The incremental
reparser will prefer to reparse their values during reparsing, saving cache
memory.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="error-recovering"><a class="header" href="#error-recovering">Error Recovering</a></h1>
<p>Once the node variant parser takes control flow, it has to parse the input
stream regardless of its content. It must consume at least one token from this
stream (if the stream is non-empty, and unless the node variant is a root node)
and must return a fully initialized instance of the corresponding node variant.</p>
<p>In other words, variant parsers behave eagerly in an attempt to parse the input,
regardless of the context from which they were called.</p>
<p>Given that the input stream is potentially an arbitrary sequence of tokens, the
parser must do its best to recognize the rule on this stream and is subject to
heuristic error recovery.</p>
<p>The generated parser performs error recovery whenever it encounters a token that
is not expected in the current parse state.</p>
<p>For instance, if we are parsing a set of identifiers separated by commas and the
end user forgets to put a comma between two identifiers, the parser might decide
to continue parsing from the next identifier, yielding a parse error at the
position where the comma was absent (a so-called "insert recovery").</p>
<p>The generated parser performs such recoveries based on preliminary compile-time
static analysis of the rule expression. However, it usually prefers a "panic
recovery" strategy by default, which is the most common error recovery approach
in LL grammars.</p>
<h2 id="panic-recovery"><a class="header" href="#panic-recovery">Panic Recovery</a></h2>
<p>In the panic recovery mode, if the parser encounters a token that is not
expected in the current parse position, it eagerly consumes this token and the
following tokens until it finds the next token from which it can resume the
normal parsing process from its current parse state.</p>
<p>This approach generally works well in many cases, except that the parser might
consume too many tokens before finding something meaningful to resume. Sometimes
it is better to halt the parsing process earlier and return control flow to the
ascending parser. For example, if we are parsing Rust's <code>let x</code> syntax and
encounter another <code>let</code> token before reading the variable identifier, it would
be better to halt the parsing of the current let-statement, assuming that the
user started another statement in the ascending context.</p>
<p>In the macro, you can specify a set of panic-recovery halting tokens using
the <code>#[recovery(...)]</code> macro attribute.</p>
<p>In
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_grammar/syntax.rs#L46">JSON example</a>,
we specify the following recovery configuration:</p>
<pre><code class="language-rust noplayground">#[recovery(
    $BraceClose,
    $BracketClose,
    [$BraceOpen..$BraceClose],
    [$BracketOpen..$BracketClose],
)]
pub enum JsonNode {
    // ...
}</code></pre>
<p>This configuration will be applied to all parsing rules, but you can override it
for specific rules using the same macro attribute.</p>
<p>In the example above, we configure two halting tokens: "BraceClose" and
"BracketClose". Additionally, we set up so-called recovery
groups (<code>[$BraceOpen..$BraceClose]</code>). The group consists of two tokens: the open
token and the close token of the group. Whenever the recoverer encounters an
open token of the group followed consistently by the close token somewhere else,
it omits the entire sequence of tokens surrounded by the open and close tokens,
regardless of whether the surrounded content contains halting tokens. In other
words, the recoverer considers a system of nested groups as a whole to be
skipped during recovery.</p>
<p>In more realistic grammar than JSON, such as Rust syntax, you would probably use
semicolons and the statement starting tokens ("let", "use", etc.) as common
halting tokens, and the open-close braces as groups.</p>
<h2 id="mismatched-captures"><a class="header" href="#mismatched-captures">Mismatched Captures</a></h2>
<p>If during error recovery the recoverer fails to recognize a token or a node that
is a target for capturing, the parser sets enum variant fields to reasonable
defaults:</p>
<ul>
<li>TokenRef or NodeRef fields will be set to a nil value.</li>
<li>Vectors will be left empty or partially completed (if the parser managed to
successfully pass some of the repetition iterations).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="debugging-1"><a class="header" href="#debugging-1">Debugging</a></h1>
<p>When designing a syntax parser, it can be useful to perform quick and
straightforward observations of the parser's step-by-step actions.</p>
<p>The built-in
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.Node.html#method.debug">Node::debug</a>
function accepts a string of the source code text and prints to the terminal the
hierarchical structure that shows how the parser descends into the node variant
parsing procedures and what tokens these procedures consumed. Additionally, it
will include the points where the parser detected syntax errors.</p>
<p>For example, the following code:</p>
<pre><code class="language-rust noplayground">use lady_deirdre::syntax::Node;
    
JsonNode::debug(r#"{
    "foo": true,
    "bar": [123 "baz"]
}"# );</code></pre>
<p>will print something like this:</p>
<pre><code class="language-text"> Root {
     Object {
         $BraceOpen
         $Whitespace
         Entry {
             String {
                 $String
             } String
             $Colon
             $Whitespace
             True {
                 $True
             } True
         } Entry
         $Comma
         $Whitespace
         Entry {
             String {
                 $String
             } String
             $Colon
             $Whitespace
             Array {
                 $BracketOpen
                 Number {
                     $Number
                 } Number
                 $Whitespace
                 --- error ---
                 String {
                     $String
                 } String
                 $BracketClose
             } Array
         } Entry
         $Whitespace
         $BraceClose
     } Object
 } Root
</code></pre>
<h2 id="errors-printing"><a class="header" href="#errors-printing">Errors Printing</a></h2>
<p>Note that in the above example, the parser encountered a syntax error when
parsing the JSON array (missing a comma between <code>123</code> and <code>"baz"</code>).</p>
<p>You can generically iterate and print syntax errors using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.SyntaxError.html#method.display">SyntaxError::display</a>
function.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{syntax::SyntaxTree, units::Document};

// Parsing the syntax and lexis of the source code into the immutable Document.
let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{
    "foo": true,
    "bar": [123 "baz"]
}"#);

for error in doc.errors() {
    println!("{:#}", error.display(&amp;doc));
}</code></pre>
<p>This code will print annotated snippets of the source code, pointing to the
fragments where the errors occur, along with the default generated error
messages.</p>
<pre><code class="language-text">   ╭──╢ Unit(1) ╟──────────────────────────────────────────────────────────────╮
 1 │ {                                                                         │
 2 │     "foo": true,                                                          │
 3 │     "bar": [123 "baz"]                                                    │
   │                ╰╴ missing ',' in Array                                    │
 4 │ }                                                                         │
   ├───────────────────────────────────────────────────────────────────────────┤
   │ Array syntax error.                                                       │
   ╰───────────────────────────────────────────────────────────────────────────╯
</code></pre>
<h2 id="syntax-tree-printing"><a class="header" href="#syntax-tree-printing">Syntax Tree Printing</a></h2>
<p>Finally, using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/trait.CompilationUnit.html#method.display">CompilationUnit::display</a><sup class="footnote-reference"><a href="#treedisplay">1</a></sup>
method, you can print the output syntax tree to the terminal.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    syntax::SyntaxTree,
    units::{CompilationUnit, Document},
};

let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{
    "foo": true,
    "bar": [123 "baz"]
}"#);

println!("{:#}", doc.display(&amp;doc.root_node_ref()));</code></pre>
<p>Outputs:</p>
<pre><code class="language-text">Root(entry: 0) {
    object: Object(entry: 1) {
        start: $BraceOpen(chunk_entry: 0) {
            string: "{",
            length: 1,
            site_span: 0..1,
            position_span: 1:1 (1 char),
        },
        entries: [
            Entry(entry: 2) {
                key: String(entry: 3) {
                    value: $String(chunk_entry: 2) {
                        string: "\"foo\"",
                        length: 5,
                        site_span: 6..11,
                        position_span: 2:5 (5 chars),
                    },
                },
                value: True(entry: 4) {
                    token: $True(chunk_entry: 5) {
                        string: "true",
                        length: 4,
                        site_span: 13..17,
                        position_span: 2:12 (4 chars),
                    },
                },
            },
            Entry(entry: 5) {
                key: String(entry: 6) {
                    value: $String(chunk_entry: 8) {
                        string: "\"bar\"",
                        length: 5,
                        site_span: 23..28,
                        position_span: 3:5 (5 chars),
                    },
                },
                value: Array(entry: 7) {
                    start: $BracketOpen(chunk_entry: 11) {
                        string: "[",
                        length: 1,
                        site_span: 30..31,
                        position_span: 3:12 (1 char),
                    },
                    items: [
                        Number(entry: 8) {
                            value: $Number(chunk_entry: 12) {
                                string: "123",
                                length: 3,
                                site_span: 31..34,
                                position_span: 3:13 (3 chars),
                            },
                        },
                        String(entry: 9) {
                            value: $String(chunk_entry: 14) {
                                string: "\"baz\"",
                                length: 5,
                                site_span: 35..40,
                                position_span: 3:17 (5 chars),
                            },
                        },
                    ],
                    end: $BracketClose(chunk_entry: 15) {
                        string: "]",
                        length: 1,
                        site_span: 40..41,
                        position_span: 3:22 (1 char),
                    },
                },
            },
        ],
        end: $BraceClose(chunk_entry: 17) {
            string: "}",
            length: 1,
            site_span: 42..43,
            position_span: 4:1 (1 char),
        },
    },
}
</code></pre>
<div class="footnote-definition" id="treedisplay"><sup class="footnote-definition-label">1</sup>
<p>Keep in mind that this function accepts either a TokenRef or a
NodeRef. Supplying a NodeRef of a syntax tree branch allows you to print only
the subtree of this branch, while providing a TokenRef enables you to print
detailed metadata about the referred token.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="syntax-tree"><a class="header" href="#syntax-tree">Syntax Tree</a></h1>
<p>The syntax API shares many similarities with the lexis API architecture:</p>
<ol>
<li>The syntax grammar, implemented by
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.Node.html">Node</a>
type, is distinct from the syntax tree manager responsible for actual parsing
and storage of the syntax tree.</li>
<li>The syntax tree manager implements
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxTree.html">SyntaxTree</a>
trait, providing access to the parsed syntax tree through its functions.</li>
<li>There are several syntax manager implementations with distinct sets of
features and performance characteristics.</li>
<li>Individual nodes within the syntax tree are addressed using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.NodeRef.html">NodeRef</a>
referential object, which points to concrete node instances owned by the
syntax tree manager.</li>
</ol>
<p>The simplest implementation of the syntax tree manager is
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.ImmutableSyntaxTree.html">ImmutableSyntaxTree</a>,
which performs one-time parsing without incremental reparsing capabilities but
has the fastest computation performance.</p>
<p>This object accepts a token cursor providing access to the input stream. For
example, you can obtain this cursor from the TokenBuffer.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    lexis::{SourceCode, TokenBuffer},
    syntax::{ImmutableSyntaxTree, SyntaxTree},
};

let tokens = TokenBuffer::&lt;JsonToken&gt;::from(r#"{
    "foo": true,
    "bar": [123, null]
}"#);

// Parsing the entire set of tokens in the token buffer.
let tree = ImmutableSyntaxTree::&lt;JsonNode&gt;::parse(tokens.cursor(..));

// Ensuring that the ImmutableSyntaxTree successfully parsed
// the input stream without syntax errors.
assert!(tree.errors().next().is_none());</code></pre>
<p>The above code is verbose because it requires manual setup of the TokenBuffer
and its token cursor.</p>
<p>More commonly, we can utilize the
immutable <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html">Document</a>,
which is backed by the TokenBuffer and ImmutableSyntaxTree under the hood.
Through this object, we can directly scan and parse the source code text. This
object implements both the SourceCode and SyntaxTree traits, allowing us to
access the lexical structure of the compilation unit as well.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{syntax::SyntaxTree, units::Document};

let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{
   "foo": true,
   "bar": [123, null]
}"#);

assert!(doc.errors().next().is_none());</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="node-references"><a class="header" href="#node-references">Node References</a></h1>
<p>Instances of nodes in the syntax tree are owned by the syntax tree manager
(e.g., by the Document or ImmutableSyntaxTree).</p>
<p>Similar to the TokenRef reference used to access individual tokens in the source
code,
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.NodeRef.html">NodeRef</a>
referential object is used to obtain access to instances of syntax tree nodes.</p>
<p>NodeRefs are cheap to copy and are lifetime-independent objects representing
globally unique composite numeric indices. However, their functions require
references to the syntax tree managers in order to dereference corresponding
nodes owned by the manager. It's important to note that a NodeRef could
potentially represent an invalid reference if the node was removed.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    syntax::{NodeRef, PolyRef, SyntaxTree},
    units::Document,
};

let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{
   "foo": true,
   "bar": [123, null]
}"#);

// Returns a referential object that points to the root of the syntax tree.
let root_ref: NodeRef = doc.root_node_ref();

// Documents always have a root.
assert!(root_ref.is_valid_ref(&amp;doc));
assert!(!root_ref.is_nil());

let Some(JsonNode::Root {object,..}) = root_ref.deref(&amp;doc) else {
    // Validity checked above.
    unreachable!();
};

// Nil NodeRefs are intentionally invalid references within any compilation unit.
assert!(!NodeRef::nil().is_valid_ref(&amp;doc));
assert!(NodeRef::nil().is_nil());
assert!(NodeRef::nil().deref(&amp;doc).is_none());</code></pre>
<h2 id="polymorphic-references"><a class="header" href="#polymorphic-references">Polymorphic References</a></h2>
<p>Since both NodeRef and TokenRef can serve as types for the children of syntax
tree nodes, they both implement a generic
trait <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.PolyRef.html">PolyRef</a>
that provides common functions for both.</p>
<p>For example,
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.PolyRef.html#tymethod.span">PolyRef::span</a>
returns the site span of the referred object's bounds.</p>
<p>The PolyRef trait is an object-safe trait, useful for handling tree children
without breaking the call chain. For instance, if you are confident that a
particular instance of a PolyRef type is a NodeRef, you can use
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.PolyRef.html#tymethod.as_node_ref">PolyRef::as_node_ref</a>
function to cast the instance to a NodeRef; otherwise, it returns a nil NodeRef
without causing a panic if the instance is not a NodeRef.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    lexis::{Position, ToSpan},
    syntax::{PolyRef, SyntaxTree},
    units::Document,
};

let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{
   "foo": true,
   "bar": [123, null]
}"#);

let root_span = doc
    .root_node_ref()
    .as_node_ref() // We are confident that `root_node_ref` returns a NodeRef.
    .span(&amp;doc)
    .unwrap() // We are confident that the root NodeRef is a valid reference.
    .to_position_span(&amp;doc)
    .unwrap(); // Site span can be casted to a Position span.

assert_eq!(root_span, Position::new(1, 1)..Position::new(4, 2));</code></pre>
<p>Finally, Lady Deirdre provides an owned version of the PolyRef trait, known
as <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/enum.PolyVariant.html">PolyVariant</a>.
PolyVariant is a simple enum with NodeRef and TokenRef variants. You can convert
either of these referential objects into a PolyVariant using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.PolyRef.html#tymethod.as_variant">PolyRef::as_variant</a>
function whenever you need a generic owned referential object for the
compilation unit's content.</p>
<p>Note that PolyVariant itself also implements the PolyRef trait.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="tree-inspection"><a class="header" href="#tree-inspection">Tree Inspection</a></h1>
<h2 id="query-nodes-manually"><a class="header" href="#query-nodes-manually">Query Nodes Manually</a></h2>
<p>When you have a NodeRef reference, you can inspect the structure of the tree
locally around this node by directly dereferencing node instances.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{syntax::SyntaxTree, units::Document};

let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{
   "foo": true,
   "bar": [123, null]
}"#);

let root_ref = doc.root_node_ref();

let Some(JsonNode::Root { object, .. }) = root_ref.deref(&amp;doc) else {
    panic!();
};

let Some(JsonNode::Object { entries, .. }) = object.deref(&amp;doc) else {
    panic!();
};

let Some(JsonNode::Entry { value, .. }) = entries[1].deref(&amp;doc) else {
    panic!();
};

let Some(JsonNode::Array { items, .. }) = value.deref(&amp;doc) else {
    panic!();
};

let Some(JsonNode::Number { value, .. }) = items[0].deref(&amp;doc) else {
    panic!();
};

let Some(string) = value.string(&amp;doc) else {
    panic!();
};

assert_eq!(string, "123");</code></pre>
<p>Alternatively, the above code could be rewritten in a more compact way using the
NodeRef's inspection functions without breaking the call chain.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{syntax::SyntaxTree, units::Document};

let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{
   "foo": true,
   "bar": [123, null]
}"#);

let string = doc
    .root_node_ref()
    .get_child(&amp;doc, "object")
    .get_child(&amp;doc, "entries") // returns the first entry
    .next_sibling(&amp;doc) // gets the second entry
    .get_child(&amp;doc, "value")
    .get_child(&amp;doc, "items") // returns the first item
    .get_token(&amp;doc, "value")
    .string(&amp;doc)
    .unwrap();

assert_eq!(string, "123");</code></pre>
<p>Each of these functions is infallible; they will return
a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.NodeRef.html#method.nil">nil</a>
NodeRef if they cannot fulfill the request. Therefore, we should be confident
about the node configuration we are trying to query.</p>
<h2 id="depth-first-traversing"><a class="header" href="#depth-first-traversing">Depth-First Traversing</a></h2>
<p>You can perform a depth-first traversal of the entire syntax tree or a specific
branch using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxTree.html#method.traverse_tree">SyntaxTree::traverse_tree</a>
and <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxTree.html#method.traverse_subtree">SyntaxTree::traverse_subtree</a>
functions, respectively.</p>
<p>Both functions require a visitor object to be passed as an argument. This object
should implement
a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.Visitor.html">Visitor</a>
trait, which includes functions that will be triggered when the traversal
procedure visits a node or token in the tree, according to the node-child
relationships between the nodes.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    lexis::TokenRef,
    syntax::{PolyRef, SyntaxTree, Visitor},
    units::Document,
};

let doc = Document::&lt;JsonNode&gt;::new_immutable( r#"{
    "foo": true,
    "bar": [123, null]
}"#);

doc.traverse_tree(&amp;mut MyVisitor(&amp;doc));

struct MyVisitor&lt;'a&gt;(&amp;'a Document&lt;JsonNode&gt;);

impl&lt;'a&gt; Visitor for MyVisitor&lt;'a&gt; {
    fn visit_token(&amp;mut self, token_ref: &amp;TokenRef) {
        println!("Token\n{}", token_ref.display(self.0));
    }
    
    fn enter_node(&amp;mut self, node_ref: &amp;NodeRef) -&gt; bool {
        println!("Enter\n{}", node_ref.display(self.0));
    
        // Tells the traverser to continue descending into this node's branch.
        true
    }
    
    fn leave_node(&amp;mut self, node_ref: &amp;NodeRef) {
        println!("Leave\n{}", node_ref.display(self.0));
    }
}</code></pre>
<p>The visitor is a stateful object that you can mutate during tree traversal. You
can use this mechanism to collect common metadata from the syntax tree.</p>
<p>The <em>enter_node</em> function returns a boolean value that controls whether to
further descend into the entered node branch.</p>
<p>The <em>leave_node</em> function effectively visits the tree in reverse order.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="hand-written-parsers"><a class="header" href="#hand-written-parsers">Hand-Written Parsers</a></h1>
<p>The following chapters cover more advanced topics, providing an in-depth
exploration of the anatomy of Lady Deirdre's parsers. They will guide you on how
to override parsers generated by the Node macro with manually implemented parse
functions.</p>
<p>One common case where you might want to implement the parse procedure manually
is infix expression parsing. Infix expressions usually require left recursion,
which cannot be directly expressed in terms of LL(1) grammars.</p>
<p>These chapters will guide you through
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/tree/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/expr_parser">Expr Parser</a>
example. This example demonstrates how to parse boolean expressions
(e.g., <code>(true | false) &amp; true</code>) using the Pratt algorithm.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="overriding-a-parser"><a class="header" href="#overriding-a-parser">Overriding a Parser</a></h1>
<p>To recap,
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/derive.Node.html">Node derive macro</a>
automatically implements parse procedures for each enum variant annotated with
the <code>#[rule(...)]</code> macro attribute. Inside the rule, you write a regex-like
parse expression in terms of the LL(1) grammars used by the macro to generate
the parse procedure. This determines the leftmost set of tokens from which
the procedure starts parsing. The leftmost set is used when you descend into
this variant in another variant's rule.</p>
<p>There is a possibility to replace the generated parse procedure with a manually
written Rust function using the <code>#[parser(...)]</code> macro attribute.</p>
<p>This attribute accepts a Rust expression that must return an instance of the
enum that represents the parsing result product. As an input, you would use
the <code>session</code> variable, which is a mutable reference to
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html">SyntaxSession</a>
that represents the current state of the parsing environment.</p>
<p>Usually, inside this expression, you would call your parsing function passing
the <code>session</code> variable as an argument.</p>
<p>From the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/expr_parser/syntax.rs#L57">Expr Parser</a> example:</p>
<pre><code class="language-rust noplayground">
#[derive(Node)]
#[token(BoolToken)]
#[trivia($Whitespace)]
pub enum BoolNode {
    #[root]
    #[rule(expr: Expr)]
    Root {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        expr: NodeRef,
    },

    #[rule($ParenOpen | $True | $False)] // Leftmost set.
    #[denote(EXPR)]
    #[describe("expression", "&lt;expr&gt;")]
    #[parser(parse_expr(session))] // Overridden parser.
    Expr {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        content: NodeRef,
    },
    
    //...
    
    #[denote(AND)]
    #[describe("operator", "&lt;and op&gt;")]
    And {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        left: NodeRef,
        #[child]
        right: NodeRef,
    },
    
    //...
}</code></pre>
<h2 id="leftmost-set-is-required"><a class="header" href="#leftmost-set-is-required">Leftmost Set is Required</a></h2>
<p>Note that even though we are overriding the parse procedure for the
<em>BoolNode::Expr</em> enum variant via the <code>#[parser(parse_expr(session))]</code> macro
attribute, we still have to specify the <code>#[rule($ParenOpen | $True | $False)]</code>
attribute too.</p>
<p>The macro requires this attribute because it needs to know the leftmost set of
the parser. Specifically, when we refer to the <em>Expr</em> variant inside the
<em>Root</em>' s <code>#[rule(expr: Expr)]</code> parse expression, the macro knows that the Expr
parser would start parsing from the "ParenOpen", "True", or "False" tokens as
described in its rule.</p>
<p>Certainly, you don't need to reimplement the entire grammar of the overridden
parse function inside the <code>#[rule(...)]</code> attribute (the macro will ignore it
anyway). Instead, it would be enough just to enumerate the leftmost tokens via
the <code>|</code> choice operator.</p>
<h2 id="variants-denotation"><a class="header" href="#variants-denotation">Variants Denotation</a></h2>
<p>Another thing to notice in this snippet is that the <em>BoolNode::And</em> variant does
not have a rule attribute, but instead, it has a pair of <code>#[denote(AND)]</code>
and <code>#[describe("operator", "&lt;and op&gt;")]</code> macro attributes.</p>
<p>We don't specify the "rule" attribute here because we are going to parse this
variant manually inside the "parse_expr" function too.</p>
<p>The <strong>denote</strong> attribute informs the macro that this variant is subject to
parsing (even if it does not have an explicitly expressed grammar rule) and
therefore is a legitimate part of the syntax tree.</p>
<p>The macro allows us to specify the <code>#[child]</code>, <code>#[parent]</code>, and other similar
fields in the denoted variants, assuming that their values will be assigned
manually. But more importantly, the macro reserves a parse rule number for the
denoted variant that we will use inside the manually written parser to address
this variant. The number can be accessed through the type's constant with the
name that we specify inside the attribute (<code>BoolNode::AND</code> in this case).</p>
<p>If the variant is denoted but does not have a rule, the macro additionally
requires specifying the <strong>describe</strong> attribute, which provides the end-user
facing description of this syntax tree node variant. The first parameter is a
string that describes the general class of this node variant (<code>"operator"</code>), and
the second one is a more specific description of this particular
variant (<code>"&lt;and op&gt;"</code>). Lady Deirdre will use this metadata to format error
messages for the syntax errors.</p>
<p>Finally, the variants with the rule attribute are assumed to be denoted
implicitly. We don't need to denote them manually, but as a rule of thumb, it is
recommended denoting and describing all enum variants regardless.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="syntax-session"><a class="header" href="#syntax-session">Syntax Session</a></h1>
<p>Inside the hand-written parse function, you will use the <code>session</code> variable
provided by the macro-generated code when it invokes this function.</p>
<p>The variable is of
type <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html">SyntaxSession</a>,
which provides an interface to read input tokens and manage the output syntax
tree.</p>
<p>The final goal of the parse function is to read some tokens from the syntax
session to recognize the target grammar rule and initialize and return an
instance of the syntax tree node as a result of the parsing procedure.</p>
<h2 id="input-tokens-stream"><a class="header" href="#input-tokens-stream">Input Tokens Stream</a></h2>
<p>The SyntaxSession trait is at first place a supertrait
of <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.TokenCursor.html">TokenCursor</a>,
representing an input stream for the parser.</p>
<p>From this interface, you can read tokens' metadata ahead of the current stream
position. For example, the <code>session.token(0)</code> function returns the first token
that has not been consumed yet, <code>session.token(1)</code> reads the next token, and so
on. Other similar lookahead functions allow you to observe more metadata about
the tokens<sup class="footnote-reference"><a href="#string">1</a></sup>. However, typically, the syntax parser should only rely on
the token instances when making a decision to change its own inner parse
state<sup class="footnote-reference"><a href="#lookahead">2</a></sup>.</p>
<p>None of these lookahead functions move the input stream forward. Once your parse
algorithm has observed a few tokens ahead, analyzed them, and made a decision to
actually "consume" these tokens, the algorithm calls
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.TokenCursor.html#tymethod.advance">TokenCursor::advance</a>
function, which consumes one token and moves the stream position to the next
token,
or <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.TokenCursor.html#tymethod.skip">TokenCursor::skip</a>,
which allows you to consume several tokens.</p>
<p>For instance, in
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/expr_parser/parser.rs#L271">Expr Parser</a>
example, we are parsing a sequence of whitespaces iteratively by reading
the tokens one by one:</p>
<pre><code class="language-rust noplayground">fn skip_trivia&lt;'a&gt;(session: &amp;mut impl SyntaxSession&lt;'a, Node = BoolNode&gt;) {
    loop {
        // Looking ahead at the next token.
        let token = session.token(0);

        // If the token is not a whitespace token, finish the parse procedure.
        if token != BoolToken::Whitespace {
            break;
        }

        // Otherwise, if the token is a whitespace, consume it, and resume
        // the loop from the next token. 
        session.advance();
    }
}</code></pre>
<p>Note that the above function, as a helper function in the overall procedure,
could potentially parse zero tokens. However, the general algorithm is required
to consume at least one token from the non-empty input stream.</p>
<div class="footnote-definition" id="string"><sup class="footnote-definition-label">1</sup>
<p>For instance, <code>session.string(0)</code> would return a substring of the
source code text covered by the first token.</p>
</div>
<div class="footnote-definition" id="lookahead"><sup class="footnote-definition-label">2</sup>
<p>Furthermore, ideally, the parser should look ahead at no more than
a single token ahead of the stream position (<code>session.token(0)</code>). The fewer
tokens you look ahead, the better incremental reparsing performance you would
gain. However, this is not a strict requirement. Looking at a few tokens ahead
is generally acceptable.</p>
</div>
<h2 id="error-recovering-1"><a class="header" href="#error-recovering-1">Error Recovering</a></h2>
<p>If the parsing algorithm hasn't finished yet but encounters an unexpected token
in the middle of the parsing procedure — a token that normally shouldn't exist
in the input stream based on the current parse state — this is a syntax error.</p>
<p>Conventionally, in a hand-written parser, you should follow the same error
recovery approaches common for parsers generated by the macro. More likely, you
would use the <a href="syntax/error-recovering.html#panic-recovery">panic recovery</a> procedure.</p>
<p>To avoid manually reimplementing the panic recovery algorithm and to be
consistent with the auto-generated parsers, Lady Deirdre exposes
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.Recovery.html">Recovery</a>
configurable object that implements this algorithm, which is also used inside
the macro-generated code.</p>
<p>The Recovery object has the same configuration options that you would use inside
the <code>#[recovery(...)]</code> macro attribute:
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.Recovery.html#method.unexpected">Recovery::unexpected</a>
function adds a halting token, and
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.Recovery.html#method.group">Recovery::group</a>
function adds a group of tokens that should be treated as a whole.</p>
<p>It is assumed that this object will be constructed upfront in the const context
and stored in a static for fast reuse.</p>
<p>Depending on the parsing procedure complexity, you may want to prepare several
Recovery objects for various types of syntax errors. For instance, in
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/expr_parser/parser.rs#L54">Expr Parser</a>
example, there are three prepared Recovery objects: one to recover from syntax
errors in the operators, one for operands, and one for errors inside
the parentheses.</p>
<pre><code class="language-rust noplayground">static OPERAND_RECOVERY: Recovery =
    // Creates an unlimited recovery configuration without groups
    // and halting tokens.
    Recovery::unlimited() 
        // Adds a group of parenthesis tokens.
        // The sequence of tokens like `(...)` will be consumed as a whole
        // during the panic recovery.
        .group(BoolToken::ParenOpen as u8, BoolToken::ParenClose as u8)
        // If the recoverer encounters a `)` token somewhere outside of any
        // group, it halts the recovery procedure (the halting token will
        // not be consumed).
        .unexpected(BoolToken::ParenClose as u8);</code></pre>
<p>To apply the panic recovery procedure, you call
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.Recovery.html#method.recover">Recovery::recover</a>
function, passing it the <code>session</code> variable and the set of tokens the recoverer
should look for. The function will consume as many tokens as needed according to
the configured rules and will return an object describing whether the procedure
managed to find the required token or failed to do so due to a specific
reason (e.g., a halting token has been reached).</p>
<p>Regardless of the recovery result, you should report the error using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html#tymethod.failure">SyntaxSession::failure</a>
function.</p>
<pre><code class="language-rust noplayground">// A set of tokens that we expect as the leftmost token of an operand.
static OPERAND_TOKENS: TokenSet = TokenSet::inclusive(&amp;[
    BoolToken::True as u8,
    BoolToken::False as u8,
    BoolToken::ParenOpen as u8,
]);

// ...

fn parse_operand&lt;'a&gt;(
    session: &amp;mut impl SyntaxSession&lt;'a, Node = BoolNode&gt;,
    context: NodeRule,
) -&gt; NodeRef {
    loop {
        let token = session.token(0);

        match token {
            // Handling expected tokens.
            BoolToken::True =&gt; return parse_true_operand(session),
            BoolToken::False =&gt; return parse_false_operand(session),
            BoolToken::ParenOpen =&gt; return parse_group(session),

            // Otherwise, try to recover using the panic recovery algorithm.
            _ =&gt; {
                // A SiteRef of where the unexpected token was encountered.
                let start_site_ref = session.site_ref(0);

                // Runs the recovery procedure. This function possibly consumes
                // some tokens from the input stream (using `session`).
                let result = OPERAND_RECOVERY.recover(session, &amp;OPERAND_TOKENS);

                // A SiteRef of where the recoverer finishes.
                let end_site_ref = session.site_ref(0);

                // Regardless of the recovery result, the syntax error has
                // to be reported.
                session.failure(SyntaxError {
                    span: start_site_ref..end_site_ref,
                    context,
                    recovery: result,
                    expected_tokens: &amp;OPERAND_TOKENS,
                    expected_nodes: &amp;EMPTY_NODE_SET,
                });

                // If the recoverer failed to recover, finish the parse loop;
                // otherwise, resume parsing from the recovered token stream
                // position.
                if !result.recovered() {
                    return NodeRef::nil();
                }
            }
        }
    }
}</code></pre>
<h2 id="rules-descending"><a class="header" href="#rules-descending">Rules Descending</a></h2>
<p>Whenever your parser needs to descend into other rules, you basically have two
options:</p>
<ol>
<li>Call
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html#tymethod.descend">SyntaxSession::descend</a>
function, which gives control flow back to the parsing environment.</li>
<li>Create and parse the node manually using a pair of
functions: <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html#tymethod.enter">SyntaxSession::enter</a>
and <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html#tymethod.leave">SyntaxSession::leave</a>.</li>
</ol>
<p>The result of the <em>descend</em> function would be similar to if the parsing
environment parsed the requested node: it will advance the token cursor of
the <code>session</code> to as many tokens as needed to cover the parsing rule, it will add
a branch of nodes to the syntax tree as a result of parsing, and it will return
you a NodeRef reference of the top node of the branch. Basically, the <em>descend</em>
function performs a normal parsing procedure, except that in practice, during
incremental reparsing, this function could potentially utilize the parsing
environment's inner cache to bypass real parsing steps.</p>
<p>You should prefer to use the <em>descend</em> function on
the <a href="syntax/syntax-grammar.html#incremental-reparsing">primary nodes</a> whenever possible.</p>
<p>In
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/expr_parser/parser.rs#L230">Expr Parser</a>
example, we are using this method to descend into the subexpression when parsing
the expression group surrounded by the <code>(...)</code> parentheses.</p>
<pre><code class="language-rust noplayground">fn parse_group&lt;'a&gt;(
   session: &amp;mut impl SyntaxSession&lt;'a, Node = BoolNode&gt;,
) -&gt; NodeRef {
    // Consumes the opening "(" token.
    session.advance();

    // Skips whitespaces in between.
    skip_trivia(session);

    // Parses the inner expression.
    let inner = session.descend(BoolNode::EXPR);

    // In the rest of the code, we are parsing the closing ")" token and return
    // the `inner` NodeRef to the parsed subexpression.
}</code></pre>
<p>Calling the <em>descend</em> function requires you to follow the same requirements as
if you were descending into the rule from
the <a href="syntax/syntax-grammar.html#rule-expressions">Node macro expression</a>:</p>
<ol>
<li>Left recursion is forbidden. You should not call this function at the
beginning of the parse procedure if descending into this rule could directly
or indirectly lead to recursive calling of the current parsing procedure.
Such a call is likely to result in infinite recursion. However, descending
into the same rule in the middle of the parsing is perfectly fine. In
particular, the <code>parse_group</code> function recursively descends into the
same <code>parse_expr</code> procedure because we forcefully consume the <code>(</code> token
before the call.</li>
<li>The variant you descend to must have a parser. The variant should have
a <code>#[rule(...)]</code>.</li>
</ol>
<p>The second method allows you to parse the subnode manually and is generally not
restricted to the above limitations.</p>
<p>Calling the <em>enter</em> function starts node parsing. Calling the <em>leave</em> function
finishes the subparser and returns the syntax session to parsing of the parent
node. The <em>enter</em> and <em>leave</em> functions must be properly balanced: entering into
the subparse context must always be enclosed by leaving the context.</p>
<p>In the <em>leave</em> function, you specify the instance of the node that is the
product of the subparser. This function returns a NodeRef of the product
deployed to the syntax tree (similarly to the <em>descend</em> function).</p>
<pre><code class="language-rust noplayground">fn parse_true_operand&lt;'a&gt;(
   session: &amp;mut impl SyntaxSession&lt;'a, Node = BoolNode&gt;,
) -&gt; NodeRef {
    // Starts "true" node parsing.
    session.enter(BoolNode::TRUE);

    // Consumes the "true" token.
    session.advance();

    // A NodeRef of the syntax tree node currently being parsed.
    let node = session.node_ref();
    
    // A NodeRef of the parent node that we parsed before entering into
    // the "true" node subparser.
    let parent = session.parent_ref();

    // Finishes "true" node subparser, and returns its NodeRef.
    return session.leave(BoolNode::True { node, parent });
}</code></pre>
<p>Note that both <em>descend</em> and <em>enter</em> functions require the rule number as an
argument. Having this number, the parsing environment reveals nesting between
the parsing procedures, which is specifically important for building the parser
tree.</p>
<p>These numbers are the constants that were specified in the <code>#[denote(TRUE)]</code>
macro attributes when we set up the derive macro.</p>
<h2 id="left-recursion"><a class="header" href="#left-recursion">Left Recursion</a></h2>
<p>Lady Deirdre follows an approach to handling left recursion by lifting syntax
tree nodes to their siblings, such that the node becomes a child of its former
sibling.</p>
<p>When parsing code such as <code>true &amp; false</code>, first, you parse the <code>true</code> operand.
If the input stream finishes at this step, you return this node as the result
product of parsing. Otherwise, when the parser encounters an <code>&amp;</code> token, it
starts a new binary operator parser immediately lifting the previously created
operand to the current operator's context, then parses the second operand and
finishes the operator parser. You can repeat this procedure iteratively to
create a left-rotated binary tree.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html#tymethod.lift">SyntaxSession::lift</a>
function "transplants" the syntax tree branch created just before we enter the
new node subparser to the context of this subparser. In particular, this
function automatically changes the parent NodeRef of the former sibling to the
node that we start parsing.</p>
<p>From the operator parser of
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/expr_parser/parser.rs#L90">Expr Parser</a>
example:</p>
<pre><code class="language-rust noplayground">BoolToken::And =&gt; {
    if binding &gt;= 2 {
        return accumulator;
    }

    // The `accumulator` is the result product of the overall parse procedure.
    let left = accumulator;

    // Entering into the `&amp;` operator subparser.
    let node = session.enter(BoolNode::AND);
 
    // The accumulated product could be Nil due to syntax errors.
    // In this case, we should not and cannot lift it.
    if !left.is_nil() {
        // Makes the former accumulated node the child (the left-hand operand)
        // of the currently parsed operator.
        session.lift(&amp;left);
    }

    let parent = session.parent_ref();

    // Consumes the `&amp;` token.
    session.advance();
    skip_trivia(session);

    // Parses the right-hand side of the operator.
    let right = parse_operator(session, BoolNode::AND, 2);

    // Finishes operator subparser, and sets the result to the `accumulator`
    // for reuse on the next loop step.
    accumulator = session.leave(BoolNode::And {
        node,
        parent,
        left,
        right,
    });
}</code></pre>
<h2 id="nodes-relations"><a class="header" href="#nodes-relations">Nodes Relations</a></h2>
<p>In contrast to the macro-generated parsers, in the hand-written parser, you have
to instantiate and properly initialize the instance of the node manually: when
you return the final result from the overall parse procedure, and when you
finish the inner subparsers via the <em>leave</em> function.</p>
<p>To set up the node-to-parent relation, you can use
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html#tymethod.parent_ref">SyntaxSession::parent_ref</a>
function that returns a NodeRef reference to the parent node in the syntax tree
of the currently parsed node.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html#tymethod.node_ref">SyntaxSession::node_ref</a>
returns a NodeRef reference of the currently parsed node that will be deployed
into the syntax tree when the parser finishes parsing (or subparsing) process.</p>
<p>To set up the child NodeRefs, you can use the result of the <em>descend</em> and
<em>leave</em> functions.</p>
<p>Whenever the parse procedure encounters syntax errors that cannot be recovered,
the parser function should set the child references to the most reasonable
defaults following the same <a href="syntax/error-recovering.html#mismatched-captures">approach</a>
as in the macro-generated parsers.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="pratts-algorithm"><a class="header" href="#pratts-algorithm">Pratt's Algorithm</a></h1>
<p>In this chapter, I will explain how the algorithm implemented in the
hand-written parser in
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/tree/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/expr_parser">Expr Parser</a>
example works in general. You may find this approach useful for programming
languages with infix expressions (math expressions with binary operators).</p>
<p>To recall, the example parses expressions of simple boolean logic: <code>true</code>
and <code>false</code> are the atomic operands of the expression, <code>_ &amp; _</code> and <code>_ | _</code> are
conjunction and disjunction binary operators respectively, where the conjunction
has a priority over disjunction (<code>true &amp; false | false &amp; true</code>
means <code>(true &amp; false) | (false &amp; true)</code>). Finally, the language has a
parenthesis grouping operator (e.g., <code>(true | false)</code>).</p>
<p>In theory, we could describe such a language in terms of the ordinary LL(1)
grammar, for example, by parsing lists of operands separated by the operator
tokens and disregarding the operators' precedence, assuming that the operator
precedence will be established in the semantic analysis stage manually and based
on the lists' content. However, such an approach is generally acceptable, but it
is usually more convenient to work with an already prepared binary tree that
properly reflects operands nesting.</p>
<p>Parsing binary trees with left and right recursion is generally impossible in
LL-parsers because these parsers' grammar cannot express left recursion.
However, inside the hand-written recursive descending parser, we can bypass this
limitation.</p>
<p>The approach used behind the example
utilizes <a href="https://en.wikipedia.org/wiki/Operator-precedence_parser#Pratt_parsing">Pratt's Parsing Algorithm</a>.</p>
<p>The idea is that we associate each operator with a numeric priority, usually
called a <em>binding power</em>: 0 for unbound precedence, 1 for the <code>|</code> operator, and
2 for the <code>&amp;</code> operator<sup class="footnote-reference"><a href="#binding">1</a></sup>. There are two mutually recursive functions:
the <code>parse_operator</code> function that parses a sequence of operators from the token
stream in accordance with the specified binding power, and the <code>parse_operand</code>
function that parses the atomic operand ("true" or "false"), or a parenthesis
operator (which we treat as an operand too).</p>
<p>The parsing procedure starts by entering into the <em>parse_operator</em> function with
zero binding power (which means that the function should attempt to parse all
input tokens).</p>
<p>First, this function parses an operand by calling the <em>parse_operand</em> function
and stores the result in the <code>accumulator</code> variable. The first operand that we
parsed is going to be the left-hand operand.</p>
<p>Then the function enters a loop where it parses the next incoming pairs of
operator tokens and the right-hand operands and reduces them to the left-rotated
binary tree using the <em>accumulator</em>:</p>
<ol>
<li>Whenever the loop encounters the next operator token, it checks if this
operator has the equal or higher binding power than the current one. If not,
it breaks the loop.</li>
<li>Otherwise, the loop consumes the token and parses the right-hand side operand
by recursively calling the <em>parse_operator</em> function <strong>with the binding power
of this operator</strong>.</li>
<li>Finally, the loop folds the current <em>accumulator</em> as the left-hand side of
the operation and the result of the right-hand side parsing product into a
binary node representing this operation and stores it in the accumulator
again, resuming the loop.</li>
<li>The loop finishes when it encounters the end of the token stream input or
the <code>)</code> token that denotes that the function reached the end of the
expression inside the <code>(...)</code> grouping expression.</li>
</ol>
<pre><code class="language-rust noplayground">fn parse_operator&lt;'a&gt;(
    session: &amp;mut impl SyntaxSession&lt;'a, Node = BoolNode&gt;,
    context: NodeRule,
    binding: u8, // Current Binding Power
) -&gt; NodeRef {
    let mut accumulator = parse_operand(session, context);

    loop {
        // Skipping the whitespaces between operands and operators.
        skip_trivia(session);

        // Looking ahead at the next token.
        let token = session.token(0);

        match token {
            // `&amp;` operator encountered.
            BoolToken::And =&gt; {
                // Check the current binding power with the operator's binding
                // power.
                if binding &gt;= 2 {
                    return accumulator;
                }
                
                // Folds the current accumulator as the left-hand operand and
                // the next right-hand operand into a single binary node.

                let left = accumulator;

                let node = session.enter(BoolNode::AND);

                if !left.is_nil() {
                    session.lift(&amp;left);
                }

                let parent = session.parent_ref();

                session.advance(); // Consumes the operator token.
                skip_trivia(session);

                // Parses the right-hand side with the operator's binding power (2).
                let right = parse_operator(session, BoolNode::AND, 2);

                // Finishes folding and stores the result in the accumulator.
                accumulator = session.leave(BoolNode::And {
                    node,
                    parent,
                    left,
                    right,
                });
            }

            BoolToken::Or =&gt; {
                if binding &gt;= 1 {
                    return accumulator;
                }

                // The same procedure, but uses the binding power 1 when parsing
                // the right-hand side.

                // ...
            }

            // The end of the input has been reached.
            // Breaking the loop and returning the accumulated result.
            BoolToken::ParenClose | BoolToken::EOI =&gt; return accumulator,

            _ =&gt; {
                // Syntax error handler
            }
        }
    }
}</code></pre>
<p>The <em>parse_operand</em> function, in turn, parses just a single operand ("true" or
"false") or a parenthesis operator, which is treated as an operand too.</p>
<pre><code class="language-rust noplayground">fn parse_operand&lt;'a&gt;(
    session: &amp;mut impl SyntaxSession&lt;'a, Node = BoolNode&gt;,
    context: NodeRule,
) -&gt; NodeRef {
    loop {
        let token = session.token(0);

        match token {
            BoolToken::True =&gt; return parse_true_operand(session),
            BoolToken::False =&gt; return parse_false_operand(session),
 
            // Recursively descends into the `parse_operator` function again
            // with binding power 0 when parsing the inner expression
            // inside `(...)`.
            BoolToken::ParenOpen =&gt; return parse_group(session),

            _ =&gt; {
                // Syntax error handler.
            }
        }
    }
}</code></pre>
<p>The above algorithm effectively constructs a left-rotated binary tree. However,
the algorithm could be easily extended to cover more cases:</p>
<ul>
<li>
<p>If you assign even binding powers to the operators (<code>&amp;</code> power is 20, <code>|</code> power
is 10), you can easily turn any operator into the right-recursive by passing
the one binding power less to the right-hand side parsers
(e.g., <code>parse_operator(session, BoolNode::AND, 19)</code> turns the conjunction
operator into the right recursive operator).</p>
</li>
<li>
<p>The unary operators without the right-hand side could be parsed the same way,
except that in the <em>parse_operator</em> function, you don't need to parse the
right-hand side.</p>
</li>
<li>
<p>The unary operators without the left-hand side could be parsed in the
<em>parse_operand</em> function that would recursively call the <em>parse_operator</em>
function with the corresponding operator's binding power to parse the
right-hand side.</p>
</li>
</ul>
<div class="footnote-definition" id="binding"><sup class="footnote-definition-label">1</sup>
<p>Some operators obviously could share the same binding power. For
example, the "+" and "-" operators in arithmetic expressions would have the same
priority, and therefore the same binding power.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="documents"><a class="header" href="#documents">Documents</a></h1>
<p>A Document is the primary object designed to store the source code text of a
compilation unit, along with its lexical and syntax structures. It ensures all
three components remain synchronized.</p>
<p>This object has two
constructors: <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html#method.new_mutable">Document::new_mutable</a>
and <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html#method.new_immutable">Document::new_immutable</a>.</p>
<p>Both constructors take the source code text as the initial input for the
Document. The first constructor creates a Document that supports write
operations, allowing for the editing of arbitrary source code spans within the
document's text. The second constructor creates a Document that does not support
write operations but is slightly faster during the document's creation.</p>
<p>To edit a mutable Document, you use
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html#method.write">Document::write</a>
function. Thisfunction takes an arbitrary span of the source code text that you
wish to rewrite and the text you want to insert in place of the specified span.
It rescans the tokens of the affected source code fragment (localized to the
span) and incrementally reparses the part of the syntax tree related to these
changes. The mutable Document is specifically designed to be efficient for write
operations. Incremental updates typically take milliseconds, even for large
compilation units, making it feasible to write into the mutable Document with
each end-user keystroke.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{lexis::SourceCode, units::Document};

let mut doc = Document::&lt;JsonNode&gt;::new_mutable(r#"{ "foo": 123 }"#);

doc.write(9..12, "456");

assert_eq!(doc.substring(..), r#"{ "foo": 456 }"#);</code></pre>
<p>If the compiler serves the dual purpose of being a programming language compiler
that compiles the entire codebase at once, and a language server that
continuously analyzes a dynamically evolving compilation project, you can
optimize the program's performance by switching between immutable and mutable
documents depending on the current mode of the program.</p>
<h2 id="loading-by-parts"><a class="header" href="#loading-by-parts">Loading By Parts</a></h2>
<p>When the content of a file is being transferred in parts, for example, through a
network or by loading the file from disk in chunks, you can create
a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenBuffer.html">TokenBuffer</a>
and continuously append these chunks into the buffer.</p>
<p>Once the file loading is complete, you can use this token buffer as input for
the Document constructor.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    lexis::{SourceCode, TokenBuffer},
    units::Document,
};

// Ideally, you can use `TokenBuffer::with_capacity()` if the final length of
// the file is known upfront.
let mut buf = TokenBuffer::new();

buf.append(r#"{ "foo": "#);
buf.append(r#"123 }"#);

let doc = Document::&lt;JsonNode&gt;::new_immutable(buf);

assert_eq!(doc.substring(..), r#"{ "foo": 123 }"#);</code></pre>
<p>This approach is likely more efficient than writing the chunks to the end of a
mutable Document. TokenBuffer is more efficient for lexical scanning when new
fragments are being appended, and this method postpones the syntax parsing of
the not-yet-completed source code text.</p>
<h2 id="syntax-less-documents"><a class="header" href="#syntax-less-documents">Syntax-less Documents</a></h2>
<p>Sometimes, you may want to use the Document to store just the source code text
and the lexical analysis of the file, bypassing the syntax analysis stage. For
example, a mutable Document can be used as a simple storage of strings with
random read/write access.</p>
<p>In this case, you can use
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.VoidSyntax.html">VoidSyntax</a>
helper object to enforce the Document to bypass syntax analysis.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{lexis::SourceCode, syntax::VoidSyntax, units::Document};

let mut doc = Document::&lt;VoidSyntax&lt;JsonToken&gt;&gt;::new_mutable(r#"{ "foo": 123 }"#);

doc.write(9..12, "456");

assert_eq!(doc.substring(..), r#"{ "foo": 456 }"#);</code></pre>
<p>The above document has full capabilities of
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/trait.SourceCode.html">SourceCode</a>
trait, but
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxTree.html">SyntaxTree</a>
implementation represents a dummy syntax tree with just a single root node that
covers empty text.</p>
<h2 id="documents-identification"><a class="header" href="#documents-identification">Documents Identification</a></h2>
<p>Each instance of the Document (and similar source code storage objects such as
the TokenBuffer) has a globally unique identifier within the current process.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html#method.id">Document::id</a>
function returns an object of
type <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/arena/struct.Id.html">Id</a>.
This object is Copy, Eq, and Hash, ensuring that two distinct instances of
documents have distinct identifiers.</p>
<p>Related objects of a Document, such
as <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.NodeRef.html">NodeRef</a>,
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/lexis/struct.TokenRef.html">TokenRef</a>,
and others, store the identifier of the document to which they belong.</p>
<p>For example, from a NodeRef referential object, you can determine the identifier
of the document to which the referred node belongs. This is particularly useful
when working with multi-document compilers.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    arena::Identifiable,
    syntax::{NodeRef, SyntaxTree},
    units::Document,
};

let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{ "foo": 123 }"#);

let root: NodeRef = doc.root_node_ref();

assert_eq!(doc.id(), root.id());</code></pre>
<h2 id="documents-naming"><a class="header" href="#documents-naming">Documents Naming</a></h2>
<p>You can assign a possibly non-unique string name to the document to simplify
document identification during debugging. For instance, you can use a file name
as a document's name.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/arena/struct.Id.html#method.set_name">Id::set_name</a>
and <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/arena/struct.Id.html#method.name">Id::name</a>
functions set and retrieve the current document name, respectively.
Additionally, the crate API uses the document's name in various debugging
functions. For example, the Display implementation of the Document object prints
the source code text to the terminal with the document name as the snippet's
caption.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{arena::Identifiable, units::Document};

let doc = Document::&lt;JsonNode&gt;::new_immutable(r#"{ "foo": 123 }"#);

// By default, the document has an empty name.
assert_eq!(doc.id().name(), "");

doc.id().set_name("Foo Doc");

assert_eq!(doc.id().name(), "Foo Doc");</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="semantics-1"><a class="header" href="#semantics-1">Semantics</a></h1>
<p>Semantic analysis is the final stage of the compilation project processing.</p>
<p>The Semantic Model is a set of user-defined data objects that collectively form
an abstraction over the syntax trees of the compilation project.</p>
<p>These data objects are constructed by associated user-defined <em>computable</em>
functions. Together, the model's data object and its associated function are
called an <em>attribute</em>.</p>
<p>Attributes are objects owned by the syntax tree nodes. By traversing the syntax
tree and querying their attribute values (the data objects of the semantic
model), you discover the semantics of the compilation project.</p>
<p>Some attributes are the inputs of the semantic model; they perform a direct
initial mapping of the syntax and lexical structures of the compilation units to
a subset of the semantic model. Other attributes infer derived information from
other attribute values.</p>
<p>Dependencies between attributes form a <em>semantic graph</em>. This graph is a
lazy-evolving, demand-driven structure and is subject to incremental
recomputations. Subsets of the graph are computed or recomputed whenever you
query attributes from these subsets. The rest of the graph remains in an
uninitialized or outdated state.</p>
<p>Lady Deirdre's semantic analysis framework helps you organize these data
structures and compute the semantic graph efficiently, possibly from multiple
concurrent threads, while keeping it in sync with changes in the source code of
the compilation project.</p>
<h2 id="chain-analysis-example"><a class="header" href="#chain-analysis-example">Chain Analysis Example</a></h2>
<p>The subchapters of this book section refer to
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/tree/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis">Chain Analysis</a>
example, which illustrates the basic concepts of the framework.</p>
<p>The example program attempts to analyze a simple programming language consisting
of nested code blocks, where each block contains variable assignment expressions
and sub-blocks.</p>
<pre><code class="language-text">{
    x = 100;

    {
        y = x;

        {
            z = y;
            w = 200;
            u = w;
        }
    }
}
</code></pre>
<p>On the left-hand side of the assignment is the name of the variable (a "Key")
being introduced. On the right-hand side is either a numeric value or a
reference to a variable introduced previously. Variables can shadow each other.</p>
<p>The compiler computes the numeric values of the variables based on the system of
references between them. For instance, the variable <code>z</code> in the above snippet has
a value of <code>100</code> because it refers to the variable <code>y</code>, which in turn refers to
the variable <code>x</code>, having a numeric value of <code>100</code>.</p>
<p>The non-incremental approach to this problem is straightforward. We can create a
hashmap ("namespace") with the keys representing variable names and the values
representing the currently inferred numbers for these variables. Then, we
perform a depth-first traversal through the entire graph. Whenever we encounter
an assignment expression, we insert an entry into the map with the key from the
left-hand side of the expression and a value that is either a number from the
right-hand side or, if the right-hand side is a reference, we retrieve the
numeric value associated with that reference from the same map. After processing
each assignment expression, we associate the key of that expression with the
inferred number.</p>
<p>The above approach is inefficient in practice for two reasons:</p>
<ol>
<li>In a code editor, the end-user typically views just one screen of the source
code text at a time. Therefore, computing the entire tree is unnecessary most
of the time.</li>
<li>Rerunning this procedure on every end-user's keystroke is necessary to keep
the assignment expressions in sync with the changes.</li>
</ol>
<p>To make this procedure more incremental and lazily computable, instead of
computing the entire procedure at once, we would split it into independent
sub-procedures localized for each code block.</p>
<p>For each code block, we will create its own namespace hashmap and traverse the
block's statements similarly to the previous approach:</p>
<ul>
<li>Whenever we encounter an assignment expression, we will try to resolve it
based on the current hashmap state as before. However, if the assignment
refers to a variable that does not exist in the map, we assume that the
referenced variable is external. In this case, we will use a string with this
reference name in the map's entry as a marker that this variable is external.</li>
<li>If we encounter a nested block, we will not descend into this block. Instead,
we will associate this block with the current copy of the hashmap.</li>
</ul>
<pre><code class="language-text">{
    x = 100; // x = 100

    // namespace copy: x = 100
    {
        y = x; // y = "x"

        // namespace copy: y = "x"
        {
            z = y; // x = "y"
            w = 200; // w = 200
            u = w; // u = 200
        }
    }
}
</code></pre>
<p>Note that the above block procedures are independent from each other. Each
block's procedure can be run in any order, and the running could be postponed
until needed.</p>
<p>To query a particular variable's resolution, first, we run the block procedure
into which it is nested. Then, we look at the local variable resolution: if the
variable was already resolved to a numeric value by its block procedure (such
as <code>x</code>, <code>w</code>, or <code>u</code> variables), we are done.</p>
<p>Otherwise, we run the procedure of the parent block and look at the copy of the
namespace that the parent's procedure assigns to our block. If the namespace
contains a numeric value for the referred token, we are done. Otherwise, we
repeat this iteration with the grandparent block, and so on, until we climb up
to the ancestor where the number is found.</p>
<p>This incremental approach offers two advantages:</p>
<ol>
<li>Whenever we need to run the block-resolution procedure, we can cache its
results as well as all intermediate resolutions. This means that the next
time we resolve this or another variable that directly or indirectly depends
on this block's local resolutions, we can retrieve their values from the
cache.</li>
<li>If the end-user types something in the block, we can erase only this block's
caches. As a result, the previously computed resolutions can still utilize
the caches that were not erased by these changes.</li>
</ol>
<p>This example illustrates the core concept of the incremental semantic analysis
framework. The source codes of the compilation units should be split into
independent scopes, so that the local semantic information can be inferred from
the states of the scopes. Then, higher-level procedures will infer higher-level
semantics from the local semantics of the scopes by seamlessly connecting their
bounds. Finally, all of these procedures would cache their results for reuse,
and these caches are subject to invalidation depending on the changes in the
source code.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="partition-into-scopes"><a class="header" href="#partition-into-scopes">Partition into Scopes</a></h1>
<p>To achieve efficiency in incremental semantic analysis, the language should
allow for partitioning of the source code of compilation units into scopes.
Within these scopes, local base semantic facts can be inferred relatively
independently from other scopes.</p>
<p>For instance, in the Java programming language, each compilation unit (file)
introduces a Java class, which can be segmented into several abstract semantic
layers:</p>
<ul>
<li>The class type declaration layer.</li>
<li>The declaration layer for class members (fields and methods) within the class.</li>
<li>The layer for implementing methods (method bodies).</li>
</ul>
<p>Initially, we can consider each of these layers as independent from each other:
each method's body code constitutes an independent scope, each class member
signature forms an independent scope, and finally, the class type declaration
stands as a scope initially separate from its members and method
implementations.</p>
<pre>
<code>
class <span style="background: color-mix(in srgb, cyan, white 80%);">MyClass&ltT&gt</span> {
    <span style="background: color-mix(in srgb, lightsalmon, white 80%);">private T fieldFoo</span> = <span style="background: color-mix(in srgb, lightgreen, white 60%);">5</span>;
    
    <span style="background: color-mix(in srgb, lightsalmon, white 80%);">public void methodBar(int x)</span> <span style="background: color-mix(in srgb, lightgreen, white 60%);">{
        //..
    }</span>
    
    <span style="background: color-mix(in srgb, lightsalmon, white 80%);">public void methodBaz(T y)</span> <span style="background: color-mix(in srgb, lightgreen, white 60%);">{
        //..
    }</span>
}
</code>
</pre>
<p>From each of these scopes, we infer as much localized information as needed,
which we can later utilize to draw more comprehensive conclusions.</p>
<p>In the example above, from the signature of <code>methodBaz</code>, we can deduce that it
possesses a parameter of type <code>T</code>. However, solely from this declaration, we
cannot pinpoint where exactly this type has been declared. Conversely, from the
signature of <code>MyClass</code>, we gather that the class has a generic type <code>T</code> that can
be utilized within its members. Yet, we cannot determine solely from the type
signature declaration which class members specifically employ this type. By
linking these two independent pieces of information together, we can conclude
that the parameter <code>x</code> of <code>methodBaz</code> has a generic type declared in the class
signature.</p>
<p>In terms of Lady Deirdre's semantic analysis framework, the localized facts we
infer from the scopes constitute the inputs of the language's <em>semantic model</em>.</p>
<p>The semantic graph attributes, which map from the scope nodes to the semantic
model objects, serve as the entry points of the model (the input attributes).
Other attributes deduce more generalized facts based on the state of the model.</p>
<p>The granularity of the attributes within the semantic graph and the separation
of scopes in the programming language syntax are core features that render
incremental semantic analysis efficient.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="grammar-setup"><a class="header" href="#grammar-setup">Grammar Setup</a></h1>
<p>The central component of your compiler is
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Analyzer.html">Analyzer</a>
object. This object is responsible to manage the set of documents within the
compilation project and their semantic graph. Further details regarding the
Analyzer's API will be discussed in subsequent chapters. For now, our focus in
this chapter will be on configuring the programming language grammar.</p>
<p>The first generic parameter <code>N</code> of the Analyzer represents the type of the
language grammar. Essentially, this parameter denotes the type of the syntax
tree node. However, to fully describe the grammar, including semantics, you need
to extend this enum type with additional metadata:</p>
<ol>
<li>Annotate enum variants that serve as the top nodes of the scopes with
the <code>#[scope]</code> macro attribute.</li>
<li>Add a semantics field to each parsable (and denoted) enum variant, annotated
with <code>#[semantics]</code>.</li>
<li>Optionally, you can specify the syntax tree classifier using
the <code>#[classifier]</code> macro attribute.</li>
</ol>
<p>From
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/tree/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis">Chain Analysis</a>
example:</p>
<pre><code class="language-rust noplayground">#[derive(Node)]
#[token(ChainToken)]
#[trivia($Whitespace)]
#[classifier(ChainNodeClassifier)] // Nodes classifier (this attribute is optional).
pub enum ChainNode {
    #[root]
    #[rule(block: Block)]
    Root {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        block: NodeRef,
        
        // Fields annotated with this macro attribute must be present in each
        // variant body, and they must be of type `Semantics`.
        #[semantics] 
        semantics: Semantics&lt;VoidFeature&lt;ChainNode&gt;&gt;,
    },

    #[rule($BraceOpen statements: (Block | Assignment)* $BraceClose)]
    #[scope] // This node is the top node of the scope.
    Block {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        statements: Vec&lt;NodeRef&gt;,
        #[semantics]
        semantics: Semantics&lt;BlockSemantics&gt;,
    },

    #[rule(key: Key $Assign value: (Ref | Num) $Semicolon)]
    Assignment {
        #[node]
        node: NodeRef,
        #[parent]
        parent: NodeRef,
        #[child]
        key: NodeRef,
        #[child]
        value: NodeRef,
        #[semantics]
        semantics: Semantics&lt;VoidFeature&lt;ChainNode&gt;&gt;,
    },
    
    // ...
}</code></pre>
<h2 id="semantics-field"><a class="header" href="#semantics-field">Semantics Field</a></h2>
<p>Each variant in the Node enum must contain a semantics field annotated with
the <code>#[semantics]</code> attribute and of
type <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Semantics.html">Semantics</a>.</p>
<p>This field will be automatically initialized<sup class="footnote-reference"><a href="#handwritten">1</a></sup> and managed by the
macro-generated code.</p>
<p>Through this field, you can access semantic graph attributes that describe the
semantics specific to each node.</p>
<p>The Semantic object is parameterized by a user-defined type, typically a struct
type, enumerating all semantic attributes logically associated with the node. In
the example above, the Semantics of the <code>ChainNode::Block</code> variant is
parameterized by the <code>BlockSemantics</code> type.</p>
<p>If a node variant doesn't have any attributes, you can parameterize its
Semantics object with
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.VoidFeature.html">VoidFeature</a>
type, as seen in the <code>Root</code> and <code>Assignment</code> node variants.</p>
<div class="footnote-definition" id="handwritten"><sup class="footnote-definition-label">1</sup>
<p>To initialize this field manually in the hand-written parser,
use
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Semantics.html#method.new">Semantics::new</a>
function, passing the current NodeRef obtained from
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxSession.html#tymethod.node_ref">SyntaxSession::node_ref</a>
function.</p>
</div>
<h2 id="feature-objects"><a class="header" href="#feature-objects">Feature Objects</a></h2>
<p>The type you use as a parameter of the Semantics object is called a <em>feature</em>.</p>
<p>Typically, the semantic feature is a user-defined struct type derived from the
Feature trait using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/derive.Feature.html">Feature derive macro</a>.
This structure consists of fields that are either attributes or other feature
objects.</p>
<pre><code class="language-rust noplayground">#[derive(Feature)]
#[node(ChainNode)] // Required by the macro trait.
pub struct BlockSemantics {
    #[scoped]
    pub analysis: Attr&lt;BlockAnalysis&gt;,
    pub assignments: Attr&lt;Shared&lt;BlockAssignmentMap&gt;&gt;,
    pub blocks: Attr&lt;Shared&lt;BlockNamespaceMap&gt;&gt;,
    pub namespace: Attr&lt;Shared&lt;BlockNamespace&gt;&gt;,
}</code></pre>
<p>In the above code, all fields are semantic
attributes (<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html">Attr</a>
types), but you are free to use other features as field types whenever you want
to create more complex nested structures. You can also reuse the same feature
type and attribute types in multiple places, as long as the feature or attribute
logically belongs to different syntax tree nodes. The Analyzer will treat them
as independent instances.</p>
<p>Additionally, in the above code, we annotated the <code>analysis</code> field
as <code>#[scoped]</code>. This annotation informs the Analyzer that this specific
attribute (or feature) is an entry point of the semantic model, performing the
initial inspection and mapping of the syntax tree's scoped branch to the
semantic model's initial objects.</p>
<p>Features with scoped attributes should be used as semantic objects of scoped
nodes (<code>BlockSemantics</code> is the semantics of the <code>ChainNode::Block</code>, which is
a <code>#[scope]</code>).</p>
<h2 id="attributes"><a class="header" href="#attributes">Attributes</a></h2>
<p>We will discuss attributes in more detail in the next chapters, but to give you
a brief overview, the generic parameter
of <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html">Attr</a>
specifies the type of the attribute value. This value is part of the semantic
model and can be any user-defined type (e.g., a struct or an enum) equipped with
a function that computes this value based on the syntax tree values and other
attribute values.</p>
<pre><code class="language-rust noplayground">#[derive(Default, Clone, PartialEq, Eq)]
pub struct BlockAnalysis {
    pub assignments: Shared&lt;BlockAssignmentMap&gt;,
    pub blocks: Shared&lt;BlockNamespaceMap&gt;,
}

impl Computable for BlockAnalysis {
    type Node = ChainNode;

    fn compute&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Self&gt; {
        // Computing the BlockAnalysis instances based on the inputs provided
        // by the `context`.
    }
}</code></pre>
<p>The general requirements imposed on this type are that it should implement the
Clone, Eq,
and <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.Computable.html">Computable</a>
traits.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="semantic-graph"><a class="header" href="#semantic-graph">Semantic Graph</a></h1>
<p>A semantic
attribute (<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html">Attr</a>
object) consists of a cache for a value of an arbitrary user-defined type and a
function that computes this value when invoked by the Analyzer's inner
algorithm.</p>
<p>Inside
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.Computable.html">Computable</a>
function that computes the value, you can access other attribute values, the
syntax and lexical content of the compilation units, and other Analyzer-related
elements from the <code>context</code> argument of
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.AttrContext.html">AttrContext</a>
type. This argument is the source of the inputs to the function, allowing you to
infer and return the resulting attribute value.</p>
<p>The implementation of the function should be deterministic and generally free of
side effects. Typically, it should compute the output value solely based on the
inputs.</p>
<h2 id="attribute-value"><a class="header" href="#attribute-value">Attribute Value</a></h2>
<p>What you compute inside the function depends on your semantics design. It could
be the type of a variable introduced in the source code, or the occurrences of a
particular identifier throughout the source code. Essentially, it encompasses
anything needed to express the programming language's semantic rules and to
enhance the language server, thereby assisting the end user in the code
editor<sup class="footnote-reference"><a href="#compiler">1</a></sup>.</p>
<p>Typically, an attribute computes a value that logically belongs to the syntax
tree node on which it is instantiated. From the <code>context</code> argument, you can
access the NodeRef that points to the node owning this attribute. Using this
NodeRef reference, you can determine the document (by the document's id) that
contains this node and read the corresponding node instance.</p>
<pre><code class="language-rust noplayground">#[derive(Default, Clone, PartialEq, Eq)]
pub struct BlockAnalysis {
    pub assignments: Shared&lt;BlockAssignmentMap&gt;,
    pub blocks: Shared&lt;BlockNamespaceMap&gt;,
}

impl Computable for BlockAnalysis {
    type Node = ChainNode;

    fn compute&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Self&gt; {
        // A NodeRef that points to the syntax tree node owning this
        // attribute (assumed to be a `ChainNode::Block` enum variant in this case).
        let block_ref = context.node_ref();
        
        // Requests the Document object that stores the corresponding
        // compilation unit and its syntax tree in particular.
        let doc_read = context.read_doc(block_ref.id).unwrap_abnormal()?;
        let doc: &amp;Document&lt;ChainNode&gt; = doc_read.deref();

        // Dereferences the instance of the syntax tree node to iterate through
        // the block statements.
        let Some(ChainNode::Block { statements, .. }) = block_ref.deref(doc) else {
            // If we encounter that the syntax tree is broken for any reason,
            // we return the (possibly unfinished) state of the computable
            // value regardless.
            //
            // The computable functions strive to infer as much metadata
            // as possible without panicking.
            return Ok(Self::default());
        };
        
        // Traversing through the block statements.
        for st_ref in statements {
            match st_ref.deref(doc) {
                // ...
            }
        }
        
        // ...
    }
}</code></pre>
<p>Similarly to the syntax analysis stage, semantic analysis should be resilient to
errors. If the computable function cannot fully infer the target value, it
attempts to compute as much metadata as possible or fallback to reasonable
defaults without causing a panic. For this reason, most semantic model objects
in the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L147">Chain Analysis</a>
example implement the Default trait.</p>
<p>For instance, in Rust source code, when introducing a variable with <code>let x;</code>,
the variable's type depends on the initialization expression. In the
type-inference attribute's computable function, we attempt to infer the Rust
type of the variable based on known initialization points. If we cannot fully
infer the type, we may infer it to a reasonable possibility or possibilities.</p>
<div class="footnote-definition" id="compiler"><sup class="footnote-definition-label">1</sup>
<p>Attributes are general-purpose; you can store any arbitrary data
inside them, not necessarily related to language semantics only. For example,
when implementing a programming language compiler, you can store middle-end or
even back-end artifacts of the compiler in some attributes. In this sense, Lady
Deirdre's semantic analysis framework could serve as an entry point to the
middle- or back-end compiler, even though these compilation stages are not the
direct purpose of Lady Deirdre.</p>
</div>
<h2 id="the-graph"><a class="header" href="#the-graph">The Graph</a></h2>
<p>Inside the computable function of the attribute, you can read other attribute
values. This mechanism allows you to infer more specific semantic facts from
more general facts.</p>
<p>For instance, in the Chain Analysis example,
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L155">LocalResolution</a>
attribute infers let-statement references within the local block in which it was
declared based on all local assignments
(<a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L306">BlockAssignmentMap</a> attribute)
within this block.</p>
<pre><code class="language-rust noplayground">#[derive(Default, Clone, PartialEq, Eq)]
pub enum LocalResolution {
    #[default]
    Broken,
    Resolved(usize),
    External(String),
}

impl SharedComputable for LocalResolution {
    type Node = ChainNode;

    fn compute_shared&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Shared&lt;Self&gt;&gt; {
        // The NodeRef reference points to the key `ChainNode::Key` enum variant.
        let key_ref = context.node_ref();

        // The Document that owns this node's syntax tree.
        let doc_read = context.read_doc(key_ref.id).unwrap_abnormal()?;
        let doc = doc_read.deref();

        // Dereferencing the "Key" node to access its semantics.
        let Some(ChainNode::Key { semantics, .. }) = key_ref.deref(doc) else {
            return Ok(Shared::default());
        };

        // Fetches the local `ChainNode::Block`'s NodeRef within the scope of
        // which the Key node resides.
        let block_ref = semantics
            .scope_attr()
            .unwrap_abnormal()?
            .read(context)?
            .scope_ref;

        // Dereferencing this block node instance.
        let Some(ChainNode::Block { semantics, .. }) = block_ref.deref(doc) else {
            return Ok(Shared::default());
        };

        // Accessing the block's semantics.
        let block_semantics = semantics.get().unwrap_abnormal()?;

        // Reading the `BlockAssignmentMap` attribute of the Block.
        let assignments = block_semantics
            .assignments
            .read(context)
            .unwrap_abnormal()?;

        // Looking up for an entry inside this map that belongs to the key.
        let Some(resolution) = assignments.as_ref().map.get(key_ref) else {
            return Ok(Shared::default());
        };

        //  Cloning the value from the entry, which will be the value of
        // the computable attribute.
        Ok(resolution.clone())
    }
}</code></pre>
<p>In this snippet, particularly on the
line <code>block_semantics.assignments.read(context)</code>, we are reading the value of
another attribute.
The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html#method.read">Attr::read</a>
function takes the current <code>context</code> reference and returns a RAII read-guard of
the attribute's value.</p>
<p>When we read an attribute inside another attribute, we're indicating to
the <code>context</code> that the value of the reader depends on the value of what's being
read.</p>
<p>The act of reading establishes dependency relations between the attributes, so
that the cached value of the reader is subject to recomputations whenever any of
its dependencies change.</p>
<p>The system of attributes and their dependencies forms a <em>Semantic Graph</em>.</p>
<p>You don't specify this graph upfront; Lady Deirdre reveals the structure of the
graph at runtime when it calls the computable function, which tells the Analyzer
how one specific attribute depends on another.</p>
<p>This graph is dynamically evolving and potentially subject to reconfiguration as
the computable function passes through different control flow paths. However,
Lady Deirdre imposes one important limitation: the
graph <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">should not have cycles</a>.
In other words, a computable function of an attribute cannot read the value of
an attribute that directly or indirectly reads its own value.</p>
<p>In the example above, the <em>LocalResolution</em> attribute depends on the
<em>BlockAssignmentMap</em> attribute, which in turn depends on the <em>BlockAnalysis</em>
attribute, an entry-point attribute that does not read any other attributes.
Thus, this dependency chain is straightforward and does not have any cycles by
design.</p>
<p>Avoiding cyclic dependencies between attributes is a rule that you should
manually implement when designing the programming language semantics. Lady
Deirdre provides some tools to detect possible errors in the graph design, which
we will discuss in the next chapters.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="incremental-computations"><a class="header" href="#incremental-computations">Incremental Computations</a></h1>
<p>Lady Deirdre does not compute attribute values instantly. Instead, the Analyzer
computes them or retrieves them from the cache whenever you explicitly read
them. Therefore, most of the time, some attribute values exist in a
not-yet-computed or outdated state.</p>
<p>However, the Analyzer is responsible for keeping the values of the graph up to
date whenever you observe corresponding attribute values.</p>
<p>The process of synchronizing the semantic graph is called <em>validation</em>.
Conversely, marking an attribute as subject for recomputation in the graph is
called <em>invalidation</em>.</p>
<p>The inner algorithm of the Analyzer is inspired by an approach similar to the
Rust compiler's query framework, also known
as <a href="https://github.com/salsa-rs/salsa">Salsa</a>. The algorithm attempts to avoid
unnecessary recomputations of semantic graph attributes whenever possible.
However, in general, it relies on the attribute's value equality (the Eq trait
implementation on the attribute value) to determine whether the value of an
attribute that depends on this one should be recomputed.</p>
<p>The validation procedure works as follows:</p>
<ol>
<li>
<p>Whenever the end user edits the source code of the compilation unit, the
Analyzer incrementally reparses the corresponding Document of this unit.</p>
</li>
<li>
<p>Then it detects all syntax tree nodes that have been altered during
reparsing (nodes that have been updated, deleted, or created).</p>
</li>
<li>
<p>Next, the Analyzer collects all top scope nodes (the nodes annotated with
the <code>#[scope]</code> macro attribute).</p>
</li>
<li>
<p>Then, the Analyzer marks the <code>#[scoped]</code> attributes of the scope nodes as
<em>invalid</em> (subject to recomputation). At this point, the algorithm completes
the "eager" stage of the validation. It does not make any further updates to
the semantic graph values. This stage usually completes quickly.</p>
</li>
<li>
<p>When you request a particular attribute value (e.g., by traversing the syntax
tree and fetching an attribute value from the node's semantics), the
algorithm checks whether the direct or indirect dependencies of the requested
attribute are invalid (or not yet computed). In such cases, the algorithm
calls the computable functions on the <em>invalid</em> attributes, updating their
caches and propagating the changes down to the requested attribute.</p>
<p>This process may finish earlier if the algorithm determines that the
recomputation process converges to the previously stored caches (based on
equality between the cached values and the new results of the computable
function).</p>
</li>
<li>
<p>Finally, the Analyzer returns an up-to-date clone of the attribute's value
from its cache (hence, the value type should implement the Clone trait).</p>
</li>
</ol>
<h2 id="input-attributes"><a class="header" href="#input-attributes">Input Attributes</a></h2>
<p>An important aspect of this algorithm is that the Analyzer automatically
invalidates only the <code>#[scoped]</code> attributes of the <code>#[scope]</code> syntax tree nodes
whenever the end user changes the content of the syntax tree within the scope.</p>
<p>Therefore, typically only these attributes should perform the initial mapping of
the scoped syntax tree structure to the initial semantic model objects.
Informally, you can think of these attributes as the <em>input attributes</em> of the
semantic graph.</p>
<p>Any other attributes should not directly rely on the current configuration of
the compilation unit state, such as the structure of children of nodes or the
strings covered by the scanned tokens. This metadata could change over time,
and, in general, will not be detected by the validator when it validates the
caches of these attributes. If this metadata is crucial to the attribute's
computable function implementation, it should be reflected in the initial
semantic model objects by the input attributes.</p>
<p>In the Chain Analysis example, only
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L202">BlockAnalysis</a>
attribute (which is a <code>#[scoped]</code> attribute of the <code>#[scope]</code> node syntax tree
node) iterates through the block's inner let-statements and the inner blocks and
collects them into HashMaps usable for further analysis. Moreover, this
attribute does not inspect the inner structure of its nested blocks too, because
the sub-block's inner syntax structure is outside of the current block scope.</p>
<p>Other attributes directly (e.g.,
<a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L310">BlockAssignmentMap</a>)
or indirectly (e.g.,
<a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L155">LocalResolution</a>
and <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L85">GlobalResolution</a>)
read the BlockAnalysis's HashMaps, but they do not perform deeper inspection of
the node's syntax tree structure inside their computable functions.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="side-effects"><a class="header" href="#side-effects">Side Effects</a></h1>
<p>Typically, implementations of
attribute's <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.Computable.html">Computable</a>
functions should be free of side effects: their results should not rely on the
external environment state, and non-input attributes should be independent from
changes in the syntax and lexical structure of the compilation units.</p>
<p>If the implementation has side effects that cannot be avoided, you have two ways
to overcome the limitations of the validation procedure:</p>
<ol>
<li>
<p>You can invalidate any attribute manually using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html#method.invalidate">Attr::invalidate</a>
function if you are aware that the external environment state has changed.</p>
</li>
<li>
<p>Inside the computable function implementation, you can use
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.AttrContext.html#method.subscribe">Context::subscribe</a>
function to subscribe this attribute to the Analyzer-wide event that could be
triggered independently for bulk invalidation of the semantic graph
attributes subscribed to a specific event. The event object that you would
pass to this function is an arbitrary user-defined value of a numeric
type<sup class="footnote-reference"><a href="#builtinevenets">1</a></sup>.</p>
</li>
</ol>
<p>Both methods should be used conservatively as they could potentially impact the
incremental capabilities of the framework.</p>
<p>However, one scenario where you might find these mechanisms useful is when your
compiler manages several Analyzers of distinct programming languages that
logically build up a single compilation project. Within this setup, changes in
the state of one Analyzer could be propagated to some attributes of another
Analyzer's setup.</p>
<div class="footnote-definition" id="builtinevenets"><sup class="footnote-definition-label">1</sup>
<p>There are a couple of built-in events as well, such as
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/constant.DOC_UPDATED_EVENT.html">DOC_UPDATED_EVENT</a>,
which denotes document-wide edits within the specified document regardless of
the scopes. However, the majority of the value range is available for
user-defined events.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="scope-access"><a class="header" href="#scope-access">Scope Access</a></h1>
<p>For any syntax tree node with semantics, you can obtain a NodeRef reference to
the top node of the scope in which this node is nested.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Semantics.html#method.scope_attr">Semantics::scope_attr</a>
function returns a special built-in attribute that contains a NodeRef of the top
node within the node's scope. The Analyzer is responsible for maintaining the
accuracy of this attribute's value, and you can utilize it within any computable
functions.</p>
<p>For instance, in the Chain Analysis example,
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L172">LocalResolution</a>
function accesses the scope block of the <code>ChainNode::Key</code> node by utilizing this
attribute.</p>
<pre><code class="language-rust noplayground">impl SharedComputable for LocalResolution {
    type Node = ChainNode;

    fn compute_shared&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Shared&lt;Self&gt;&gt; {
        let key_ref = context.node_ref();
        let doc_read = context.read_doc(key_ref.id).unwrap_abnormal()?;
        let doc = doc_read.deref();

        let Some(ChainNode::Key { semantics, .. }) = key_ref.deref(doc) else {
            return Ok(Shared::default());
        };

        let block_ref = semantics // The semantics of the Key node.
            .scope_attr() // The scope attribute of the `Key` node.
            .unwrap_abnormal()?
            .read(context)? // Reading this attribute.
            .scope_ref; // The NodeRef of the `Block` into which this `Key` node is nested.

        let Some(ChainNode::Block { semantics, .. }) = block_ref.deref(doc) else {
            return Ok(Shared::default());
        };
        
        // ...
    }
}</code></pre>
<p>Note that the top nodes themselves are considered to be nested within their
parent scopes. The <code>ChainNode::Block</code> node, which serves as a top node of a
scope, is nested within its parent, Block<sup class="footnote-reference"><a href="#parent">1</a></sup>. By iteratively climbing up,
you will eventually reach the root of the syntax tree.</p>
<p>The <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L85">GlobalResolution</a>
attribute leverages this feature to calculate the ultimate resolution of
the <code>ChainNode::Key</code> value by ascending through the hierarchy of nested blocks.</p>
<pre><code class="language-rust noplayground">impl Computable for GlobalResolution {
    type Node = ChainNode;

    fn compute&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Self&gt; {
        let key_ref = context.node_ref();
        let doc_read = context.read_doc(key_ref.id).unwrap_abnormal()?;
        let doc = doc_read.deref();

        let Some(ChainNode::Key { semantics, .. }) = key_ref.deref(doc) else {
            return Ok(Self::default());
        };

        let key_semantics = semantics.get().unwrap_abnormal()?;

        let local_resolution = key_semantics
            .local_resolution
            .read(context)
            .unwrap_abnormal()?;

        // Checks if the `Key` has already been resolved locally.

        let mut ref_name = match local_resolution.as_ref() {
            LocalResolution::Broken =&gt; return Ok(Self::Broken),
            LocalResolution::Resolved(num) =&gt; return Ok(Self::Resolved(*num)),
            LocalResolution::External(name) =&gt; String::from(name),
        };
        
        // Otherwise, it climbs up through the system of nested blocks.

        // Fetches the NodeRef of the `Key`'s block node in a similar manner to
        // the `LocalResolution` computable function.
        let mut block_ref = semantics
            .scope_attr()
            .unwrap_abnormal()?
            .read(context)
            .unwrap_abnormal()?
            .scope_ref;

        loop {
            // Checks if the current block has the resolution we are seeking.
        
            let Some(ChainNode::Block { semantics, .. }) = block_ref.deref(doc) else {
                return Ok(Self::default());
            };

            let block_semantics = semantics.get().unwrap_abnormal()?;

            let block_namespace = block_semantics.namespace.read(context).unwrap_abnormal()?;

            match block_namespace.as_ref().namespace.get(&amp;ref_name) {
                Some(LocalResolution::Broken) =&gt; return Ok(Self::Broken),
                Some(LocalResolution::Resolved(num)) =&gt; return Ok(Self::Resolved(*num)),
                Some(LocalResolution::External(name)) =&gt; ref_name = String::from(name),
                None =&gt; (),
            }

            // Otherwise, sets the `block_ref` to the parent block of
            // the current block to continue the climbing-up iteration.

            block_ref = semantics
                .scope_attr()
                .unwrap_abnormal()?
                .read(context)
                .unwrap_abnormal()?
                .scope_ref;
        }
    }
}</code></pre>
<div class="footnote-definition" id="parent"><sup class="footnote-definition-label">1</sup>
<p>Or within the root node of the syntax tree. The root node is treated
as the default scope for the entire syntax tree.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="granularity"><a class="header" href="#granularity">Granularity</a></h1>
<p>As a general rule, it's preferable to maintain the semantic graph in a divided
manner, with small attributes that are easy to clone and compare for equality.
This ensures that each attribute value remains logically isolated from others.</p>
<p>With a granular semantic graph, the validation procedure is likely to complete
the propagation of incremental changes throughout the dependent attributes of
the graph more efficiently. This is achieved by comparing newly computed
attribute values with previous caches and stopping the propagation process if
they are found to be equal.</p>
<p>In the Chain Analysis example,
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L197">BlockAnalysis</a>
input attribute initially collects all assignment statements and inner blocks
into two dedicated maps: <code>assignments</code> and <code>blocks</code>.</p>
<pre><code class="language-rust noplayground">#[derive(Default, Clone, PartialEq, Eq)]
pub struct BlockAnalysis {
    pub assignments: Shared&lt;BlockAssignmentMap&gt;,
    pub blocks: Shared&lt;BlockNamespaceMap&gt;,
}</code></pre>
<p>Later on, these maps are utilized in
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L155">LocalResolution</a>
and
<a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L85">GlobalResolution</a>
attributes. In theory, we could directly read the <em>BlockAnalysis</em> attribute from
these computable functions. However, in practice, when the end user modifies the
content of a block, it's likely that one of the BlockAnalysis maps may remain
unchanged. Therefore, depending solely on changes in the overall BlockAnalysis
attribute to read just one of the two maps is probably unnecessary<sup class="footnote-reference"><a href="#blockanalysis">1</a></sup>.</p>
<p>For these reasons, we spread both maps into the
intermediate
<a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L310">BlockAssignmentMap</a>
and <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L337">BlockNamespaceMap</a> attributes
by cloning the hash maps into them. Subsequently, we read these maps in the
final attributes through these intermediaries independently.</p>
<p>If the <em>BlockAnalysis</em> attribute becomes invalid, both <em>BlockAssignmentMap</em> and
<em>BlockNamespaceMap</em> will be recomputed when the validation procedure refreshes
the semantic graph. However, it's possible that some of the <em>LocalResolution</em>
and <em>GlobalResolution</em> attributes will remain unaffected if the validator
detects that the intermediate attribute values haven't changed. As a result, the
entire validation procedure would proceed faster by skipping some of the heavy
computation steps.</p>
<div class="footnote-definition" id="blockanalysis"><sup class="footnote-definition-label">1</sup>
<p>This example might seem artificial, but in real-world
applications, it's probable that the input attributes for scope analysis would
comprise many more potentially independent fields.</p>
</div>
<h2 id="shared-object"><a class="header" href="#shared-object">Shared Object</a></h2>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/sync/struct.Shared.html">Shared</a>
helper object is Lady Deirdre's reference-counting thread-safe container, akin
to Rust's standard Arc, with two notable distinctions:</p>
<ol>
<li>Shared, unlike Arc, lacks a Weak counterpart. If a weak counterpart isn't
required, Shared's computation and memory performance are slightly better
than Arc's.</li>
<li>The
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/sync/struct.Shared.html#method.get_mut">Shared::get_mut</a>
function accepts <code>&amp;mut self</code>. This makes it more convenient to use when
constructing Shared in place.</li>
</ol>
<p>Shared was initially designed for Lady Deirdre's semantic analysis framework.
However, you are free to utilize it anywhere you don't require Arc's weak
counterpart as well.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::sync::Shared;

let mut shared_a = Shared::new(100);

// You can mutate the inner data in place when Shared does not have any clones yet.
*shared_a.get_mut().unwrap() += 20;

// However, to read the inner data, you need to explicitly call `.as_ref()`.
assert_eq!(*shared_a.as_ref(), 120);

// Does not clone the inner allocated data; it only creates another smart
// pointer to this allocation, similar to `Arc::clone`.
let shared_b = shared_a.clone();

assert_eq!(*shared_b.as_ref(), 120);</code></pre>
<h2 id="shared-computable"><a class="header" href="#shared-computable">Shared Computable</a></h2>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.SharedComputable.html">SharedComputable</a>
is a specialized helper trait that automatically implements the Computable trait
on the type <code>Shared&lt;T&gt;</code> if <em>SharedComputable</em> is implemented on <code>T</code>.</p>
<p>The <code>SharedComputable::compute_shared</code> function is a mandatory computation
function through which you return <code>Shared&lt;T&gt;</code> instead of <code>T</code>.</p>
<p>This trait is especially handy for propagating the Shared value through
intermediate attributes. For instance,
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L328">BlockAssignmentMap</a>
simply clones a shared map from
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L198">BlockAnalysis</a>
(which is cheap, as it merely creates a new smart pointer to the same
allocation).</p>
<pre><code class="language-rust noplayground">#[derive(Default, Clone, PartialEq, Eq)]
pub struct BlockAssignmentMap {
    pub map: HashMap&lt;NodeRef, Shared&lt;LocalResolution&gt;&gt;,
}

impl SharedComputable for BlockAssignmentMap {
    type Node = ChainNode;

    fn compute_shared&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Shared&lt;Self&gt;&gt; {
        let block_ref = context.node_ref();
        let doc_read = context.read_doc(block_ref.id).unwrap_abnormal()?;
        let doc = doc_read.deref();

        let Some(ChainNode::Block { semantics, .. }) = block_ref.deref(doc) else {
            return Ok(Shared::default());
        };

        let block_semantics = semantics.get().unwrap_abnormal()?;

        // Cloning the `BlockAnalysis::assignments` field as the result value of
        // this computable function.
        Ok(block_semantics.analysis.read(context)?.assignments.clone())
    }
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="the-analyzer"><a class="header" href="#the-analyzer">The Analyzer</a></h1>
<p>To recap,
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Analyzer.html">Analyzer</a>
serves as the central object of the compiler, managing the compilation project's
set of documents and the semantic graph.</p>
<p>The state of this object is presumed to be shared among multiple
threads<sup class="footnote-reference"><a href="#singlethread">1</a></sup>. Specifically, numerous threads can edit various
documents concurrently without blocking (provided they edit distinct documents).
Additionally, multiple threads can query the semantic graph concurrently and
often without blocking (especially when the threads query independent
attributes). However, it's not possible to edit the documents and query their
attributes simultaneously. When querying an attribute, the graph undergoes
incremental recomputations that require synchronization of its state with
changes in documents. Therefore, the content of the documents should remain
fixed at the synchronization point.</p>
<p>For this reason, the API restricts access to the Analyzer's state: at any given
time, you either <em>mutate</em> the state of the Analyzer (e.g., apply edits to the
documents) or <em>analyze</em> the current state (e.g., query attribute values).</p>
<p>The Analyzer grants access to specific operations with its data through a system
of <em>task objects</em>. You can think of a "task" as an RAII guard, through which you
gain access to specific operations on the Analyzer's data<sup class="footnote-reference"><a href="#tasks">2</a></sup>.</p>
<p>The Analyzer offers three types of task objects:</p>
<ul>
<li>The
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.AnalysisTask.html">AnalysisTask</a>:
This task allows you to query semantic graph attributes. You can have as many
simultaneous task objects of this type as you need.</li>
<li>The
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.MutationTask.html">MutationTask</a>:
With this task, you can create, edit, or remove documents, and you can trigger
analyzer-wide events. Similar to AnalysisTask, you can have multiple
simultaneous task objects of this type.</li>
<li>The
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.ExclusiveTask.html">ExclusiveTask</a>:
This task enables you to sequentially perform analysis and mutation operations
within a single thread. However, you cannot have more than one task of this
type simultaneously.</li>
</ul>
<p>You obtain the task objects by requesting them from the Analyzer. For instance,
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Analyzer.html#method.analyze">Analyzer::analyze</a>
function returns an <em>AnalysisTask</em> instance.</p>
<p>Each of these request functions could block the current thread if the Analyzer
cannot grant requested access instantly. For instance, if two threads request
analysis tasks, both of them will obtain access. However, if one thread requests
an analysis task and another thread requests a mutation task, one of the threads
will be blocked until the other releases the task object.</p>
<p>Informally, you can view the task system as a "RwLock" with complex
access-granting rules, and the task objects as "RAII guards".</p>
<div class="footnote-definition" id="singlethread"><sup class="footnote-definition-label">1</sup>
<p>Even though, it's perfectly acceptable to use it from a single
thread in a single-threaded process too.</p>
</div>
<div class="footnote-definition" id="tasks"><sup class="footnote-definition-label">2</sup>
<p>Don't be confused by the term "task". A Task Object simply grants
access to specific operations. While it's assumed that the task object would be
associated with a thread worker in the end application architecture, Lady
Deirdre doesn't manage threads itself, nor does it spawn any threads
specifically. Managing threads isn't the focus of the crate; you have the
freedom to organize the multithreaded (or single-threaded) architecture of your
program however you see fit.</p>
</div>
<h2 id="mutation-task"><a class="header" href="#mutation-task">Mutation Task</a></h2>
<p>The mutation task is utilized for creating, editing, or removing documents, as
well as triggering analyzer-wide events.</p>
<pre><code class="language-rust noplayground">let analyzer = Analyzer::&lt;ChainNode&gt;::new(AnalyzerConfig::default());

// A handle through which the task's thread could be gracefully interrupted.
// This interruption can be triggered either manually or by the Analyzer's inner
// task manager.
let handle = TriggerHandle::new();

// Requests the MutationTask.
let mut task = analyzer.mutate(&amp;handle, 1).unwrap();

// Creates a new mutable document inside the Analyzer with the initial source
// code "test".
// The function returns an identifier for the created document.
let doc_id = task.add_mutable_doc("{ x: 10; }");

// Edits the document by its ID.
// This function may block if the document is currently being edited in another
// thread within another mutation task.
task.write_to_doc(doc_id, .., "{ y: 10; }").unwrap();

// Invalidates all attributes that have been subscribed to the event.
task.trigger_event(doc_id, 1234);

// Removes the document.
task.remove_doc(doc_id).unwrap();

// Ensures that the document no longer exists in the Analyzer.
assert!(!task.contains_doc(doc_id));</code></pre>
<p>In the above code, the <code>add_mutable_doc</code> function
resembles <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html#method.new_mutable">Document::new_mutable</a>,
and the <code>write_to_doc</code> function
resembles <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/units/enum.Document.html#method.write">Document::write</a>,
except that the Document instance is managed by the Analyzer.</p>
<h2 id="analysis-task"><a class="header" href="#analysis-task">Analysis Task</a></h2>
<p>With the analysis task, you can read attributes of the semantic graph, but you
cannot edit existing documents.</p>
<pre><code class="language-rust noplayground">// Requests the AnalysisTask.
let task = analyzer.analyze(&amp;handle, 1).unwrap();

// Gets read-only access to the document by its id.
let doc_read = task.read_doc(doc_id).unwrap();
let doc = doc_read.deref();

// Searching for a `ChainNode::Key` node within the syntax tree.

let Some(ChainNode::Root { block, .. }) = doc.root_node_ref().deref(doc) else {
    panic!();
};

let Some(ChainNode::Block { statements, .. }) = block.deref(doc) else {
    panic!();
};

let Some(ChainNode::Assignment { key, .. }) = statements[0].deref(doc) else {
    panic!();
};

let Some(ChainNode::Key { semantics, .. }) = key.deref(doc) else {
    panic!();
};

let (attribute_version, resolution) = semantics
    .get()
    .unwrap()
    // The attribute of the node's semantic feature.
    .global_resolution
    // Returns a clone of the attribute's current value.
    .snapshot(&amp;task)
    .unwrap();

assert_eq!(resolution, GlobalResolution::Resolved(100));</code></pre>
<p>Note
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html#method.snapshot">snapshot</a>
function in the above code that we're calling on the <code>global_resolution</code>
attribute of the node's semantics.</p>
<p>This function executes the validation procedure and returns a pair of objects:
the Analyzer's inner version at which the value of the attribute was updated,
and a copy of the attribute's value.</p>
<p>The version number represents the inner version of the semantic graph state. The
Analyzer increments its version number each time it updates the values within
the semantic graph. This number always increases and never decreases.</p>
<p>The <em>snapshot</em> function returns the version at which the cache was updated. This
number is useful for quickly checking if the attribute has a new value by
comparing it with the version number received from this function previously.</p>
<p>The second object of the pair is a copy of the attribute's value. Unlike
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html#method.read">Attr::read</a>
function used within computable functions, which returns a reference to the
value, the <em>snapshot</em> function used externally copies the value (by cloning it).</p>
<p>For this reason, it's recommended to make the attribute's value type cheap
to copy if the attribute is intended to be observed from outside of computable
functions. Otherwise, you can wrap the value type
into <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/sync/struct.Shared.html">Shared</a>.</p>
<h2 id="exclusive-task"><a class="header" href="#exclusive-task">Exclusive Task</a></h2>
<p>You obtain the exclusive task using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Analyzer.html#method.exclusive">Analyzer::exclusive</a>
function.</p>
<p>The Analyzer grants only one instance of this type of task at a time, but this
task object provides both the analysis task and mutation task APIs.</p>
<p>The exclusive task is useful for both single-threaded and multi-threaded
compilers.</p>
<p>In some language servers and code editors, a technique used to implement
code-completion suggestions involves probing the source code by inserting a
special secret word at the position of the end user cursor. This allows
traversal of the tree to find the syntax tree node containing this word, thus
identifying the part of the syntax the user was attempting to complete. Finally,
the source code is restored by removing the inserted probing word.</p>
<p>All three steps — writing the probe word, analyzing the probed text, and
removing the probe word — should be done as a single transaction to ensure
atomicity. The exclusive task provides this atomicity, preventing other threads
from reading or changing the probed text in between.</p>
<h2 id="documents-reading"><a class="header" href="#documents-reading">Documents Reading</a></h2>
<p>From any kind of task, you can read the content of the document (both lexical
and syntactical).
The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.AbstractTask.html#method.read_doc">read_doc</a>
function returns a <em>DocumentReadGuard</em> RAII guard, through which you access the
Document object immutably. While this guard is held, attempts to mutate this
specific document (edit or remove) will be blocked. However, semantic analysis
(e.g., querying attributes) is not affected because analysis does not require
mutation of compilation units.</p>
<h2 id="shared-analyzer"><a class="header" href="#shared-analyzer">Shared Analyzer</a></h2>
<p>As the Analyzer is going to be a central object of the compiler, it's
recommended to either place it in a
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/sync/struct.Shared.html">Shared</a>
or a
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/sync/struct.Lazy.html">Lazy</a>
static for easy access from multiple threads. This is somewhat analogous to
placing a Mutex or RwLock with the program-wide state into an Arc to share it
across threads.</p>
<p>All methods of the Analyzer's API are <code>&amp;self</code> functions.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::{
    analysis::{Analyzer, AnalyzerConfig, TriggerHandle},
    sync::Lazy,
};

// This static will be initialized once you dereference it.
static MY_COMPILER: Lazy&lt;Analyzer&lt;ChainNode&gt;&gt; =
    Lazy::new(|| Analyzer::new(AnalyzerConfig::default()));

let handle = TriggerHandle::new();

let task = MY_COMPILER.mutate(&amp;handle, 1).unwrap();</code></pre>
<h2 id="single-document-compiler"><a class="header" href="#single-document-compiler">Single Document Compiler</a></h2>
<p>Sometimes, the compiler you're developing is intended to compile a programming
language without modules. For instance, vanilla JavaScript doesn't have modules;
the entire JavaScript compilation project consists of just one file (one
document).</p>
<p>In this case, you can configure the Analyzer when you instantiate it to manage
no more than a single document.</p>
<pre><code class="language-rust noplayground">use lady_deirdre::analysis::{Analyzer, AnalyzerConfig};

let mut config = AnalyzerConfig::default();

config.single_document = true;

let analyzer = Analyzer::&lt;ChainNode&gt;::new(config);</code></pre>
<p>With this configuration option, you are turning off some inner memory and
performance overhead that the Analyzer consumes to handle more than one
document.</p>
<p>However, note that the single document Analyzer is still capable of managing
more than one document, but it is likely that multi-document management would be
less efficient. Therefore, you can use this configuration option to design the
compiler to usually manage a single compilation unit but not strictly limit it
to just one unit.</p>
<h2 id="custom-hasher"><a class="header" href="#custom-hasher">Custom Hasher</a></h2>
<p>The semantic analysis framework under the hood utilizes hash maps and hash sets
to store various kinds of inner metadata. By default, these maps and sets use
Rust's
standard <a href="https://doc.rust-lang.org/std/hash/struct.RandomState.html">RandomState</a>
hasher, which prioritizes stability for specific kinds of cryptography attacks
relevant for network services. However, it is slower than other alternatives
without such guarantees.</p>
<p>Since compilers and language servers intended to run solely on local machines
usually don't require this level of security, the performance of the Analyzer
could be improved by replacing the standard hasher with a faster compatible
alternative from the Rust ecosystem, such
as <a href="https://crates.io/crates/ahash">aHash</a>.</p>
<p>To replace the hashing algorithm, you need to explicitly specify the third
generic parameter of the Analyzer with the hashing algorithm type of your
choice.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="tasks-management"><a class="header" href="#tasks-management">Tasks Management</a></h1>
<p>Under the hood, the Analyzer maintains a queue of tasks, both activated and
pending.</p>
<p>To clarify, at any given point in time, the Analyzer activates only one type of
simultaneous task objects (and no more than one exclusive task).</p>
<p>Whenever you request a task object of a particular type, the task manager
attempts to activate it immediately according to the current tasks queue. If
activation is not possible, the Analyzer blocks the current thread, enqueues the
request, and unblocks the requester thread once the inactive request in the
queue reaches activation (once all top active task objects in the queue that
block this request will be released by the concurrent threads).</p>
<h2 id="graceful-shutdown"><a class="header" href="#graceful-shutdown">Graceful Shutdown</a></h2>
<p>The job that your program's thread performs with the task object is subject to
graceful shutdown. For this reason, each task request function of the Analyzer
requires specifying the task handle through which the job could be signaled to
shut down.</p>
<pre><code class="language-rust noplayground">let handle = TriggerHandle::new();

let task = analyzer.analyze(&amp;handle, 1).unwrap();

assert!(!handle.is_triggered());
assert!(!task.handle().is_triggered());

// Signals the job for interruption.
handle.trigger();

assert!(handle.is_triggered());
assert!(task.handle().is_triggered());</code></pre>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.TriggerHandle.html">TriggerHandle</a>
is the default implementation of the handle<sup class="footnote-reference"><a href="#customhandle">1</a></sup>. This object is
thread-safe and cheap to clone. Once the handle is triggered (via
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.TaskHandle.html#tymethod.trigger">trigger</a>
function), all copies of the instance become triggered, which serves as a marker
for the job thread to gracefully finish its job.</p>
<p>You can create the handle from outside of the worker thread where you are
scheduling the worker's job and pass a copy of the handle to the worker thread.
The worker thread will use it to request the task object from the Analyzer.</p>
<p>The worker thread should periodically check the handle's triggering state. Once
the handle is triggered and if the worker hasn't completed its job yet, the
worker thread should perform the minimal amount of work required to interrupt
its job normally and drop the task object as soon as possible, releasing the
acquired access grant back to the Analyzer.</p>
<p>The Analyzer could also trigger the handle. For example, if the task manager
realizes that some thread has requested a task with higher priority and this
kind of access cannot be granted instantly because there are lesser prioritized
but still active task objects in the queue, the manager would trigger the
handles of these active tasks.</p>
<div class="footnote-definition" id="customhandle"><sup class="footnote-definition-label">1</sup>
<p>Note that Lady Deirdre allows you to create your own task
handle types with more complex triggering logic by implementing
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.TaskHandle.html">TaskHandle</a>
trait on the user-defined type. In this case, you would use this type as the
second generic parameter of
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Analyzer.html">Analyzer</a>
object.</p>
</div>
<h2 id="tasks-interruption"><a class="header" href="#tasks-interruption">Tasks Interruption</a></h2>
<p>The Analyzer itself examines the handle during the semantic graph validation
between the attribute validation bounds. If the validation procedure determines
that the handle was triggered in the middle of the analysis, the validator will
leave the semantic graph in a not-yet-completed state (without breaking its
integrity), and it will start returning
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/enum.AnalysisError.html#variant.Interrupted">Interrupted</a>
error from all corresponding functions.</p>
<p>For example,
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html#method.read">Attr::read</a>
function used inside the computable functions and
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html#method.snapshot">Attr::snapshot</a>
function used to get a copy of the attribute value from outside both would start
returning the Interrupted error.</p>
<p>Receiving this error signals that the task handle was triggered, indicating that
you are no longer able to query the semantic graph using this task object, and
that you should gracefully finish the worker's job by dropping the task object
as soon as possible.</p>
<p>When you receive this error inside the computable function, you should return
this error as well from the function.</p>
<pre><code class="language-rust noplayground">#[derive(Default, Clone, PartialEq, Eq)]
pub struct BlockAssignmentMap {
    pub map: HashMap&lt;NodeRef, Shared&lt;LocalResolution&gt;&gt;,
}

impl SharedComputable for BlockAssignmentMap {
    type Node = ChainNode;

    fn compute_shared&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Shared&lt;Self&gt;&gt; {
        log_attr::&lt;Self, H, S&gt;(context)?;

        let block_ref = context.node_ref();
        let doc_read = context.read_doc(block_ref.id).unwrap_abnormal()?;
        let doc = doc_read.deref();

        let Some(ChainNode::Block { semantics, .. }) = block_ref.deref(doc) else {
            return Ok(Shared::default());
        };

        let block_semantics = semantics.get().unwrap_abnormal()?;

        // The `?` mark would return the Interrupted error from this function if
        // the `read` function was interrupted.
        Ok(block_semantics.analysis.read(context)?.assignments.clone())
    }
}</code></pre>
<p>Note that the validator checks interruption events only between computable
function calls. In principle, it is not capable of checking this event during
function execution. To make the trigger handle state examination more granular,
you can manually check its state in long-running computable functions.</p>
<p>For instance, in
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L223">BlockAnalysis</a>
attribute of the Chain Analysis example, we are checking the interruption state
during the iteration through the assignment statements of the block.</p>
<pre><code class="language-rust noplayground">impl Computable for BlockAnalysis {
    type Node = ChainNode;

    fn compute&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Self&gt; {
        let block_ref = context.node_ref();
        let doc_read = context.read_doc(block_ref.id).unwrap_abnormal()?;
        let doc = doc_read.deref();

        let mut result = Self::default();

        let Some(ChainNode::Block { statements, .. }) = block_ref.deref(doc) else {
            return Ok(result);
        };

        let mut block_namespace = BlockNamespace::default();

        for st_ref in statements {
            // Returns an Interrupted error if the task handle had been triggered.
            context.proceed()?;

            // ...
        }

        Ok(result)
    }
}</code></pre>
<h2 id="tasks-priority"><a class="header" href="#tasks-priority">Tasks Priority</a></h2>
<p>The second argument of the task request functions (e.g., <em>analyze</em>, <em>mutate</em>,
etc.) is a numeric type denoting the task's priority.</p>
<p>The task manager attempts to prioritize tasks with a higher priority number over
tasks with a lower priority number when enqueueing the task object into the task
queue.</p>
<h2 id="bulk-interruption"><a class="header" href="#bulk-interruption">Bulk Interruption</a></h2>
<p>You can specify the minimum tasks priority level allowed in the Analyzer by
calling
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Analyzer.html#method.set_access_level">Analyzer::set_access_level</a>
function and specifying the priority threshold.</p>
<p>Calling this function will interrupt all currently active tasks with a priority
lower than the threshold.</p>
<p>Non-active pending tasks with a priority lower than the threshold will be
removed from the task queue, and the corresponding requester threads will be
unblocked, immediately
receiving <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/enum.AnalysisError.html#variant.Interrupted">Interrupted</a>
errors.</p>
<p>All future task requests with a lower priority than the current threshold will
also receive Interrupted errors.</p>
<p>This function is particularly useful for shutting down the entire compiler
gracefully. By specifying the maximum threshold value, you can enforce all tasks
of all kinds to shut down gracefully, preventing access from being granted to
any new incoming task requests.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="multi-file-analysis"><a class="header" href="#multi-file-analysis">Multi-File Analysis</a></h1>
<p>A compilation project usually consists of multiple compilation units that are
semantically connected to each other.</p>
<p>For example, a Java file may declare a class with signatures that reference
classes declared in other files within the same Java package.</p>
<p>To establish semantic relationships between these compilation units, you can
define a special analyzer-wide feature object.</p>
<p>From the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/tree/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/shared_semantics">Shared Semantics</a> example:</p>
<pre><code class="language-rust noplayground">#[derive(Node)]

// Defines a semantic feature that is shared across all documents in the Analyzer.
#[semantics(CommonSemantics)]

pub enum SharedSemanticsNode {
    // ...
}

#[derive(Feature)]
#[node(SharedSemanticsNode)]
pub struct CommonSemantics {
    pub modules: Slot&lt;SharedSemanticsNode, HashMap&lt;String, Id&gt;&gt;,
}</code></pre>
<h2 id="common-semantics"><a class="header" href="#common-semantics">Common Semantics</a></h2>
<p>The common semantics feature is a typical feature object, except that it is not
bound to any specific node within a compilation unit and is instantiated during
the creation of the Analyzer.</p>
<p>This feature is not tied to any syntax tree scope. Therefore, its members will
not be directly invalidated during the editing of the Analyzer's documents.</p>
<p>However, the members of this feature are part of the semantic graph and are
subject to the normal rules of the semantic graph, such as the prohibition of
cycles between computable functions.</p>
<p>Common semantic features typically include:</p>
<ul>
<li>Analyzer-wide reducing attributes, such as an attribute that collects all
syntax and semantic issues detected across all managed documents.</li>
<li>External configuration metadata specified via the system of
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Slot.html">Slots</a>.
For instance, a map between file names and their document IDs within the
Analyzer (as in the example above).</li>
</ul>
<p>You can access common semantics both inside and outside of computable
functions. Inside a computable function, you can access common semantics
using the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.AttrContext.html#method.common">AttrContext::common</a>
method. To access the semantics outside, you would use the
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.AbstractTask.html#method.common">AbstractTask::common</a>
method.</p>
<pre><code class="language-rust noplayground">#[derive(Clone, PartialEq, Eq)]
pub enum KeyResolution {
    Unresolved,
    Recusrive,
    Number(usize),
}

impl Computable for KeyResolution {
    type Node = SharedSemanticsNode;

    fn compute&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Self&gt; {
        // ...

        // Reading the common semantics inside the computable function.
        let modules = context.common().modules.read(context).unwrap_abnormal()?;
        
        // ...
    }
}

let handle = TriggerHandle::new();
let mut task = analyzer.mutate(&amp;handle, 1).unwrap();

let doc_id = task.add_mutable_doc("x = 10; y = module_2::b; z = module_2::c;");
doc_id.set_name("module_1");

// Modifying the Slot value of the common semantics outside.
task.common()
    .modules
    .mutate(&amp;task, |modules| {
        let _ = modules.insert(String::from("module_1"), doc_id);

        true
    })
    .unwrap();</code></pre>
<h2 id="slots"><a class="header" href="#slots">Slots</a></h2>
<p>The primary purpose of a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Slot.html">Slot</a>
is to provide a convenient mechanism for injecting configuration metadata
external to the Analyzer into the semantic graph. For instance, mapping between
file system names and the Analyzer's document IDs can be injected through a
common semantics Slot.</p>
<p>Slot is a special feature of the semantic graph that is quite similar to
attributes, except that a Slot does not have an associated computable function.
Instead, Slots have associated values of a specified type (the second generic
argument of the <code>Slot&lt;Node, ValueType&gt;</code> signature).</p>
<p>You can <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Slot.html#method.snapshot">snapshot</a>
the current Slot value outside of computable functions, and you can
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Slot.html#method.read">read</a>
Slot values within the computable functions of attributes, thereby subscribing
those attributes to changes in the Slot, much like with normal attributes.</p>
<p>By default, Slot values are set to the <code>Default</code> of the value type. You can
modify the content of the Slot value using the
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Slot.html#method.mutate">Slot::mutate</a>
method with a mutable (or exclusive) task.</p>
<pre><code class="language-rust noplayground">task.common()
    .modules
    // The `task` is a MutationTask or an ExclusiveTask.
    //
    // The provided callback accepts a mutable reference to the current
    // value of the Slot, and returns a boolean flag indicating whether the
    // value has changed.
    .mutate(&amp;task, |modules| {
        let _ = modules.insert(String::from("module_1"), doc_id);

        // Indicates that the `modules` content has been changed.
        true
    })
    .unwrap();</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h2 id="language-server-design"><a class="header" href="#language-server-design">Language Server Design</a></h2>
<p>The rationale behind the Analyzer's complex data access API is that it is
specifically designed for use in language server programs that handle language
client (code editor) requests concurrently.</p>
<p>The client of
the <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a>
notifies the server about
various events happening on the client side, allowing the server to handle these
requests concurrently in dedicated working threads.</p>
<p>For example, when the client notifies the server that the end user has opened a
file in the editor by sending the source code text, you can acquire a mutation
task and create a Document to represent this task.</p>
<p>When the end-user edits the file, the client usually sends a notification to the
server containing an edited fragment span and the text the user is typing. In
this case, you would acquire a mutation task and apply the edit to the
corresponding document.</p>
<p>When the user scrolls the document window, clicks or moves the cursor over
symbols in the source code, or requests code completion suggestions, the client
sends multiple requests to the server asking for various semantic facts about
the source code spans that the user is currently observing. The server can use
analysis tasks to query the Analyzer's document semantics and respond to these
requests accordingly.</p>
<p>The observation requests from the client can be canceled if the client decides
that a request is no longer relevant. In this case, once the server receives the
cancellation notification, it can signal the corresponding working thread to
interrupt its job by triggering the task handle used by the working thread.</p>
<p>Client-side requests can obviously conflict with each other. For example, an
incoming document edit notification would conflict with in-progress semantic
analysis requests.</p>
<p>These conflicts can be resolved through the Analyzer's task priority system.
Analysis tasks used to handle client analysis requests should typically have
lower priorities than mutation tasks handling document edits, as immediate
synchronization of changes in the source code file on the client side with the
server-side state is more important than analysis jobs.</p>
<p>Since the analysis job is subject to frequent interruptions by client-side
cancellation notifications and mutation jobs, the typical analysis job workflow
involves a loop with the following steps:</p>
<ol>
<li>At the beginning of the loop, check if the client-side request has been
canceled. If it has, break the loop and respond to the client accordingly.</li>
<li>Otherwise, acquire an analysis task from the Analyzer and execute the actual
analysis procedure based on the client request inputs.</li>
<li>If the analysis succeeds, return the response to the client with the analysis
results and finish the loop.</li>
<li>If the analysis job is interrupted because another thread with a higher
priority attempts to acquire a conflicting (mutation) task object, the
analysis worker should drop its analysis task object to allow the other
thread to fulfill its request<sup class="footnote-reference"><a href="#delay">1</a></sup>. Then, restart the loop from step one
to eventually complete the client-side analysis request.</li>
</ol>
<p>An important feature of the above procedure is that even if we drop the analysis
task in the middle of its execution, the Analyzer may still manage to complete
part of the semantic graph validations. When the analysis procedure resumes, it
is likely to execute much faster, continuing validation from the point where it
was interrupted. This approach is particularly relevant for computation-heavy
analysis procedures on highly granular semantic models.</p>
<div class="footnote-definition" id="delay"><sup class="footnote-definition-label">1</sup>
<p>At this step, you can even park or sleep the current thread for a
short amount of time to ensure that the other thread acquires the requested task
without race conditions.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="configuration-issues"><a class="header" href="#configuration-issues">Configuration Issues</a></h1>
<p>Many functions in the semantic analysis framework API can return
an <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/enum.AnalysisError.html">AnalysisError</a>,
representing either a normal result (e.g.,
an <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/enum.AnalysisError.html#variant.Interrupted">Interrupted</a>
error) or an abnormal error indicating a configuration or usage issue with the
framework.</p>
<p>For example,
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.MutationAccess.html#method.write_to_doc">write_to_doc</a>
function of the mutation task can return
a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/enum.AnalysisError.html#variant.MissingDocument">MissingDocument</a>
error if you specify a document ID that does not exist in the Analyzer (e.g., if
the document was previously removed from the Analyzer).</p>
<p>The API documentation for framework functions typically describes the types of
errors that a function can return. Depending on the situation, you may handle
certain errors manually. However, as a fallback, it is recommended to return
normal errors from functions that
return <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/type.AnalysisResult.html">AnalysisResult</a>
and to panic immediately if an abnormal error occurs. This convention helps
identify configuration or usage issues more quickly.</p>
<p>Canonical compilers written with Lady Deirdre should be designed to be
infallible. If you receive an abnormal error from a framework function, it
likely indicates a bug in your program's code that needs to be fixed.</p>
<p>In particular, the computable functions of
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L337">Chain Analysis</a>
example use
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/type.AnalysisResult.html#method.unwrap_abnormal">unwrap_abnormal</a>
helper function to filter out normal errors from abnormal ones, panicking if an
abnormal error is encountered.</p>
<pre><code class="language-rust noplayground">impl SharedComputable for BlockNamespaceMap {
    type Node = ChainNode;

    fn compute_shared&lt;H: TaskHandle, S: SyncBuildHasher&gt;(
        context: &amp;mut AttrContext&lt;Self::Node, H, S&gt;,
    ) -&gt; AnalysisResult&lt;Shared&lt;Self&gt;&gt; {
        log_attr::&lt;Self, H, S&gt;(context)?;

        let block_ref = context.node_ref();
        let doc_read = context.read_doc(block_ref.id).unwrap_abnormal()?;
        let doc = doc_read.deref();

        let Some(ChainNode::Block { semantics, .. }) = block_ref.deref(doc) else {
            return Ok(Shared::default());
        };

        // The `Semantics::get` function returns a reference to the node's
        // semantics. However, in theory, it could also return
        // an `UninitSemantics` error if the semantics of the node were not
        // properly initialized for some obscure reason.
        //
        // In such a case, the `unwrap_abnormal` function will panic accordingly.
        let block_semantics = semantics.get().unwrap_abnormal()?;

        Ok(block_semantics
            .analysis
            .read(context)
            // If the `Attr::read` function returns an Interrupted error, this
            // error will be propagated from this computable function as well.
            //
            // However, if the function returns any other type of error,
            // considered as abnormal, the `unwrap_abnormal` function will
            // also panic accordingly.
            .unwrap_abnormal()?
            .blocks
            .clone())
    }
}</code></pre>
<p>Additionally, it is recommended to log every computable function at the
beginning of its implementation. This practice aids in swiftly identifying
various issues in the attributes logic by examining the log trace.</p>
<p>In the provided snippet, the <code>log_attr</code> function generates a debug message for
the logger regarding the computable function about to be executed, along with
the syntax tree node snippet on which this attribute is being computed. This
function is implemented within the Chain Analysis example's codebase. Lady
Deirdre does not include built-in functionality for logging computable
functions, as it does not have a built-in logger and assumes that logging
infrastructure is implementation-specific.</p>
<h2 id="cycles-detection"><a class="header" href="#cycles-detection">Cycles Detection</a></h2>
<p>The absence of cycles in the semantic graph is a framework requirement that
users need to implement manually.</p>
<p>Graph cycles share similarities with unbounded infinite recursion accidentally
introduced into the source code. Lady Deirdre cannot proactively check the graph
structure because it evolves at runtime based on custom logic within computable
functions.</p>
<p>There are two primary methods for detecting accidentally introduced cycles.
Firstly, logging computable functions helps establish how attributes refer to
each other during execution via the log trace.</p>
<p>Secondly, a hard timeout limits computable function execution. Typically, if the
semantic model of the language is granular, computable functions complete
execution within a few milliseconds, even on low-end CPUs. By default, the
Analyzer sets the timeout limit to a few seconds<sup class="footnote-reference"><a href="#timeoutlimit">1</a></sup>. If a computable
function exceeds this limit, it indicates a potential issue in the semantics
design, and the corresponding analysis function (
e.g., <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html#method.snapshot">Attr::snapshot</a>)
yields
a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/enum.AnalysisError.html#variant.Timeout">Timeout</a>
error.</p>
<p>This mechanism is also useful for detecting cycles. When the semantic graph
validator encounters a cyclic reference between attributes, it deadlocks the
validation procedure. However, due to the timeout limit, the validator
eventually unblocks with a <em>Timeout</em> error.</p>
<p>During debugging (when the <code>debug_assertions</code> feature flag is enabled), the
<em>Timeout</em> error is considered abnormal. Debug builds aim to detect attributes
with long execution times and cycles in the semantic graph as early as possible
for debugging purposes. However, in production builds, <em>Timeout</em> errors are
treated as normal errors, assumed to be caused by edge cases in the project's
source code compilation, and thus handled without panic<sup class="footnote-reference"><a href="#timoutpanic">2</a></sup>.</p>
<div class="footnote-definition" id="timeoutlimit"><sup class="footnote-definition-label">1</sup>
<p>You can configure this limit via
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.AnalyzerConfig.html">AnalyzerConfig</a>
object, which you pass to the Analyzer's constructor.</p>
</div>
<div class="footnote-definition" id="timoutpanic"><sup class="footnote-definition-label">2</sup>
<p>The user of the code editor's extension would prefer the
extension to gracefully ignore specific edge cases that the plugin is unable to
handle, rather than causing the entire plugin to terminate abruptly.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="code-diagnostics"><a class="header" href="#code-diagnostics">Code Diagnostics</a></h1>
<p>While most end attributes of the semantic graph aim to infer specific semantic
facts about particular syntax tree nodes, code diagnostics (semantic errors and
warnings) are intended to be collected from the entire syntax tree.</p>
<p>To tackle this issue and improve the incremental nature of code diagnostics, you
can gather local diagnostic messages within scopes by iterating through scope
nodes and their attributes, potentially containing diagnostic issues. These
issues can then be collected into the hash set of the scope's diagnostics
attribute.</p>
<p>Subsequently, in the root node's global diagnostics attribute, you can iterate
through all local diagnostic attributes of scopes and aggregate their values
into a single set, wrapping it into
a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/sync/struct.Shared.html">Shared</a>
structure for efficient cloning. Furthermore, you can enhance the final
diagnostics set with syntax errors from the normal compilation unit by directly
reading them from the document<sup class="footnote-reference"><a href="#syntaxerror">1</a></sup>.</p>
<p>The resulting global diagnostics attribute would indirectly depend on the
majority of the semantic graph. Despite potential optimizations by the validator
due to granularity, querying this attribute could still be computationally
intensive in edge cases. To mitigate this, the language server could
periodically examine this attribute with a low-priority analysis task.</p>
<p>Moreover, when utilizing
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.Attr.html#method.snapshot">Attr::snapshot</a>
function to retrieve a copy of the current diagnostics sets, you can leverage
the version number of the attribute value to determine whether this set needs to
be republished to the client.</p>
<div class="footnote-definition" id="syntaxerror"><sup class="footnote-definition-label">1</sup>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxTree.html#method.errors">Document::errors</a>
function would provide you with an iterator over all syntax errors within the
compilation unit.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="tree-index"><a class="header" href="#tree-index">Tree Index</a></h1>
<p>The semantic analysis framework of Lady Deirdre is capable of maintaining
user-defined context-unaware indexes of the document's syntax tree nodes.</p>
<p>Examples of these indices include all methods within the document, all code
blocks, identifiers partitioned by name, and so forth.</p>
<p>Indices serve various purposes. For instance, in the previous chapter, we
discussed document-wide diagnostics, where the root's diagnostic attribute
collects local diagnostics from all scope nodes within the document. To support
this attribute, you can define an index of all scopes within the document. The
attribute will then read this class of nodes inside the computable function to
inspect all their local diagnostic attribute values.</p>
<p>Another example involves highlighting all identifiers within the code related to
a single variable. Typically, within the attributes framework, it's easier to
establish the variable usage node's definition node than the opposite relations.
When the end user clicks on the variable usage symbol in the code editor, the
language client requests from the language server all highlighted spans related
to the symbol on which the user clicks.</p>
<p>Here's how you can fulfill a request for highlighting all identifiers within the
code that relate to a single variable:</p>
<ol>
<li>Traverse the syntax tree to determine the node on which the end user
clicks<sup class="footnote-reference"><a href="#traverse">1</a></sup>.</li>
<li>Query this node's attribute to retrieve its variable definition node. At this
point, we discover two spans: the variable usage span where the user's cursor
is and the variable definition span. However, we don't yet know about other
variable usage spans within the code that would be useful for the editor's
user.</li>
<li>Query the index of all variable usages within the code with the specific
name. Some of these will be the identifiers we are looking for, while others
may be false candidates located outside the variable definition scope.</li>
<li>Since false candidates are likely to be a relatively small subset, owing to
the practice of programmers using distinct variable names, filter out these
false instances in the set. This can be achieved by querying their definition
attributes again to determine if they have the same definition node as the
one discovered in step 2.</li>
</ol>
<div class="footnote-definition" id="traverse"><sup class="footnote-definition-label">1</sup>
<p>You can utilize depth-first traversal using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/trait.SyntaxTree.html#method.traverse_tree">Document::traverse_tree</a>
function. By skipping the descent into child nodes with spans that don't cover
the targeted site, the traversal complexity averages to <code>O(ln(N))</code>, where N is
the number of nodes in the tree. In other words, traversing will typically be
quite fast.</p>
</div>
<h2 id="index-setup"><a class="header" href="#index-setup">Index Setup</a></h2>
<p>To enable the index, you need to specify the nodes classifier using
the <code>#[classifier(...)]</code> macro attribute.</p>
<pre><code class="language-rust noplayground">#[derive(Node)]
#[classifier(ChainNodeClassifier)]
pub enum ChainNode {
   // ...
}</code></pre>
<p>The parameter of this macro attribute is an arbitrary type that implements
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.Classifier.html">Classifier</a>
trait. It denotes classes of nodes, essentially serving as indices, and the
function that partitions requested nodes between these classes.</p>
<p>In
the <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/chain_analysis/semantics.rs#L411">Chain Analysis</a>
example, we define just one class for all <code>ChainNode::Key</code> nodes within the
syntax tree.</p>
<pre><code class="language-rust noplayground">#[derive(Clone, PartialEq, Eq, Hash)]
pub enum ChainNodeClass {
    AllKeys, // All keys
}

pub struct ChainNodeClassifier;

impl Classifier for ChainNodeClassifier {
    // Must match the type of the syntax tree node.
    type Node = ChainNode;
    
    // Could be any user-defined type eligible for the HashSet. 
    type Class = ChainNodeClass;

    // Given the Document and the NodeRef that points to the node inside this
    // document, this function should compute a set of classes to which this
    // node belongs, possibly returning an empty set.
    fn classify&lt;S: SyncBuildHasher&gt;(
        doc: &amp;Document&lt;Self::Node&gt;,
        node_ref: &amp;NodeRef,
    ) -&gt; HashSet&lt;Self::Class, S&gt; {
        let mut result = HashSet::with_hasher(S::default());

        let Some(node) = node_ref.deref(doc) else {
            return result;
        };

        match node {
            ChainNode::Key { .. } =&gt; {
                let _ = result.insert(ChainNodeClass::AllKeys);
            }

            _ =&gt; (),
        }

        result
    }
}</code></pre>
<p>Inside the classification function, it's recommended (and necessary) to
dereference the specified node to determine its classes. You can examine its
lexical structure but should avoid inspecting the node's parent and child node
structures, as the classification should be context-unaware. Classes of the
nodes are simple lexical classes.</p>
<p>In the above code, we classify the node by its enum discriminant only. In more
complex setups, you can use the TokenRef references of the node, as these
references are part of the node's lexical structure. For example, we could
partition the Keys by their token strings as well, using the strings as part of
the class.</p>
<h2 id="index-maintenance"><a class="header" href="#index-maintenance">Index Maintenance</a></h2>
<p>The Analyzer automatically maintains the index. During the initial parsing of
the newly created document, the Analyzer creates a document index by calling the
above function on each syntax tree node, associating each class with the set of
nodes of this class.</p>
<p>When you edit the document (using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.MutationAccess.html#method.write_to_doc">write_to_doc</a>
function), the Analyzer incrementally updates this partition based on the
changes in the structure of the syntax tree.</p>
<h2 id="index-access"><a class="header" href="#index-access">Index Access</a></h2>
<p>You can query a set of nodes of the document that belong to a specified class
both inside the computable functions of the attributes using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/struct.AttrContext.html#method.read_class">read_class</a>
function of the <code>context</code> variable, and outside using the
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/analysis/trait.AbstractTask.html#method.snapshot_class">snapshot_class</a>
function of the task object.</p>
<p>Both functions return
a <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/sync/struct.Shared.html">Shared</a>
set of the NodeRefs that point to the nodes in the document's syntax tree
belonging to the class.</p>
<p>When you query the index from inside of the computable function, the attribute
subscribes to changes in this class. Whenever the returning set changes, this
attribute will be invalidated. Therefore, you can traverse and dereference the
nodes from the returning set, and you can read their semantics too inside the
computable function of any kind of attribute. However, in general, you should
avoid inspecting these node structures more deeply.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="code-formatters"><a class="header" href="#code-formatters">Code Formatters</a></h1>
<p>Many programming language compilers and language support extensions of code
editors typically include code formatting programs. These programs take the
source code text as input and bring it to a canonical format according to the
code formatting rules.</p>
<p>Code formatting presents a challenging problem that must consider both canonical
formatting rules and the original intentions of the code author, such as
preserving empty lines between code fragments and retaining code comments on
their respective lines.</p>
<p>Lady Deirdre offers two tools to aid in implementing the code formatter:</p>
<ol>
<li>The
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/syntax/struct.ParseTree.html">ParseTree</a>
builder constructs a concrete parsing tree. Unlike abstract syntax trees, it
intentionally preserves all original source code whitespaces and comments.</li>
<li>The
<a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html">PrettyPrinter</a>
tool automatically decides on splitting the text into lines and determines
line indentation to ensure that the final lines are aligned according to the
predefined maximum line length.</li>
</ol>
<p>The parse tree builder utilizes the same syntax parser defined within the Node
derive macro. However, unlike the Document or ImmutableSyntaxTree parsers, this
parser preserves all tokens and trivia nodes, such as comments, in the concrete
parse tree. While the structure of the output concrete parse tree resembles the
syntax tree in terms of node structural nesting, the parse tree nodes include
all possibly omitted children of the syntax tree grammar, regardless of
capturing rules.</p>
<p>Nodes of the parse tree comprehensively cover the original source code without
gaps or overlaps. Consequently, the original source code text can be fully
reconstructed by traversing the tree. To simplify tree traversing, parse tree
nodes are owned by their parents.</p>
<p>The source code text is expected to be provided to the parse tree builder, and
the concrete parse tree is then used as input for the formatting tool. During
tree traversal, your program interprets the lexis and tree nesting of the
source code in accordance with your programming language formatting rules,
considering the concrete tree configuration. It then feeds the source code
tokens into the syntax-unaware Pretty Printer. The printer generates the final
output string.</p>
<p>The <a href="https://github.com/Eliah-Lakhin/lady-deirdre/tree/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_formatter">Json Formatter</a>
example demonstrates the basic usage of both tools.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="pretty-printer"><a class="header" href="#pretty-printer">Pretty Printer</a></h1>
<p>The pretty printer object operates in a syntax-unaware manner, meaning it
doesn't consider the meaning of the original grammar tokens and nodes. Instead,
it deals with its own system of abstract tokens that shape the output in terms
of string words, blanks between words, and word groups only.</p>
<p>The objective of the printer is to interpret each incoming blank token as either
a whitespace or a line break, depending on the current line length and the
preconfigured maximum line length. If the printer determines to break the line
at the location of the blank token, it will subsequently indent or dedent the
following lines in accordance with the nesting of the groups.</p>
<h2 id="printing-words"><a class="header" href="#printing-words">Printing Words</a></h2>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.word">PrettyPrinter::word</a>
function inputs a string word token into the printer, which will be printed on
the current line of the output, thus increasing the line length.</p>
<p>You invoke this function whenever encountering a parse tree token with content,
such as a keyword, identifier, or anything else besides whitespace or a line
break.</p>
<p>Additionally, you can call this function with a whitespace string to instruct
the printer to preserve the whitespace on the line regardless of the current
line length. This is useful, for instance, for comments' inner content or source
code string literals. However, it's not recommended to use this function to
forcibly break lines. In such cases, you should use the <em>hardbreak</em> function.</p>
<h2 id="blank-tokens"><a class="header" href="#blank-tokens">Blank Tokens</a></h2>
<p>To separate the words in the output of the printer, you utilize one of the
pretty printer's "blank" token functions:</p>
<ul>
<li>
<p><a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.blank">PrettyPrinter::blank</a>
is the default blank token, interpreted either as a single whitespace or a
line break. You call this function when the next word should be separated from
the previous one, possibly with a line break, depending on the printing
algorithm's decision.</p>
</li>
<li>
<p><a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.hardbreak">PrettyPrinter::hardbreak</a>
is a blank token that enforces the printer to always interpret it as a line
break. You call this function, for instance, when printing the inner content
of multi-line comments, as the structure of the comment's text typically needs
to be preserved.</p>
</li>
<li>
<p><a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.softbreak">PrettyPrinter::softbreak</a>
is similar to the <em>blank</em> function, but if the printer's algorithm decides to
preserve the next token on the line, it does not insert whitespace. This
function is useful, for example, to delimit the <code>.</code> dot tokens in a
call-chain (<code>foo.bar</code>). In such cases, you can insert a <em>softbreak</em> token
before the dot but omit the delimiter after the dot word</p>
</li>
</ul>
<h2 id="word-groups"><a class="header" href="#word-groups">Word Groups</a></h2>
<p>During the formatting process, when the current content exceeds the maximum line
length, the algorithm attempts to break the content into lines by interpreting
blank tokens as line breaks.</p>
<p>At this point, the algorithm can either interpret all blank tokens as line
breaks, resulting in consistent line splitting, or it can selectively interpret
some blank tokens, maximizing the utilization of line space.</p>
<p>Consistent line splitting is preferable for source code blocks, such as JSON
objects.</p>
<pre><code class="language-text">{
    "foo": 123,
    "bar": 456,
    "baz": 789
}
</code></pre>
<p>For enumerations of simple items (e.g., JSON arrays), inconsistent breaking is
more suitable.</p>
<pre><code class="language-text">[123, 456, 789, 1011, 1213, 1516, 1718, 1920, 2122,
    2324, 2526, 2728]
</code></pre>
<p>Content breaking occurs within word groups. To initiate a new group, you use
either <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.cbox">PrettyPrinter::cbox</a>
or <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.ibox">PrettyPrinter::ibox</a>.
The former
begins a consistent word group, while the latter starts an inconsistent group.</p>
<p>Each group must be closed by
calling <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.end">PrettyPrinter::end</a>.</p>
<p>Both <em>cbox</em> and <em>ibox</em> functions accept indentation level shifting for the
group, represented by a signed integer. Positive values increase the inner
content's indentation, negative values decrease it (with zero having no effect).
When the printer breaks the content inside the group, each new line is indented
with whitespace according to the current indentation level.</p>
<h2 id="overriding-indentations"><a class="header" href="#overriding-indentations">Overriding Indentations</a></h2>
<p>You can manually adjust line indentation by calling
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.indent">PrettyPrinter::indent</a>
function <strong>immediately after</strong> submitting any of the blank tokens. If the
algorithm interprets the submitted token as a line break, the next line, as well
as all subsequent lines, will be shifted accordingly.</p>
<h2 id="keeping-content-in-line"><a class="header" href="#keeping-content-in-line">Keeping Content In Line</a></h2>
<p>In general, the algorithm aims to break lines as early as possible so that
parental word groups are split by lines, while leaf groups remain in line.</p>
<pre><code class="language-text">{
    "foo": [123, 456, 789, 1011, 1213, 1516, 1718, 1920, 2122]
}
</code></pre>
<p>This approach is generally suitable for most practical use cases. However, there
are situations where it's preferable to keep the parental content aligned in
line and splitting of the nested groups instead.</p>
<p>In such cases, you can utilize
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.neverbreak">PrettyPrinter::neverbreak</a>
function, which instructs the printer to reset the current line length counter
to zero. Consequently, the algorithm assumes that the previously submitted text
fits on the line, and begins splitting from the subsequent nested submissions.</p>
<pre><code class="language-text">{ "foo": [123, 456, 789, 1011, 1213, 1516, 1718,
    1920, 2122] }
</code></pre>
<h2 id="trailing-commas"><a class="header" href="#trailing-commas">Trailing Commas</a></h2>
<p>Depending on the language grammar, some languages allow leaving a trailing comma
at the end of lists (e.g., Rust and JavaScript, but not JSON). This ensures
better readability when the list is split into multiple lines, as the last item
receives a trailing comma, but the comma is omitted if the content remains in a
single line.</p>
<p>This formatting rule depends on whether the algorithm decides to insert a line
break at the blank token. To address this, you can use
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.pre_break">PrettyPrinter::pre_break</a>
and <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.PrettyPrinter.html#method.pre_space">PrettyPrinter::pre_space</a>
functions to configure the preceding blank token.</p>
<p>Both functions must be called <strong>immediately after</strong> submitting the blank token.
The first function, <em>pre_break</em>, specifies a word that will be inserted before
the line break (at the end of the previous line), while the second function,
<em>pre_space</em>, inserts the specified word otherwise (the word will appear before
the whitespace when paired with the <em>blank</em> function).</p>
<p>When your program formats a comma-separated list, you can insert regular
<code>,</code> commas after each intermediary item and a normal blank token after each
comma. At the end of the list, after the last submitted item, you can submit a
<em>softbreak</em> token and configure it with <code>pre_break(',')</code>, ensuring that if this
trailing blank token receives a line break, the last line of the list will be
appended with a comma.</p>
<div style="break-before: page; page-break-before: always;"></div><!------------------------------------------------------------------------------
  This file is part of "Lady Deirdre", a compiler front-end foundation
  technology.

  This work is proprietary software with source-available code.

  To copy, use, distribute, or contribute to this work, you must agree to
  the terms of the General License Agreement:

  https://github.com/Eliah-Lakhin/lady-deirdre/blob/master/EULA.md

  The agreement grants a Basic Commercial License, allowing you to use
  this work in non-commercial and limited commercial products with a total
  gross revenue cap. To remove this commercial limit for one of your
  products, you must acquire a Full Commercial License.

  If you contribute to the source code, documentation, or related materials,
  you must grant me an exclusive license to these contributions.
  Contributions are governed by the "Contributions" section of the General
  License Agreement.

  Copying the work in parts is strictly forbidden, except as permitted
  under the General License Agreement.

  If you do not or cannot agree to the terms of this Agreement,
  do not use this work.

  This work is provided "as is", without any warranties, express or implied,
  except where such disclaimers are legally invalid.

  Copyright (c) 2024 Ilya Lakhin (Илья Александрович Лахин).
  All rights reserved.
------------------------------------------------------------------------------->
<h1 id="snippets"><a class="header" href="#snippets">Snippets</a></h1>
<p>When a compilation project has errors or warnings, it is usually more beneficial
for the end user to print source code snippets in the terminal, annotating the
fragments where the issues occur.</p>
<p>While there are several similar tools in the Rust ecosystem that you can use
with this crate, Lady Deirdre provides its own solution as well.</p>
<p>The <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.Snippet.html">Snippet</a>
is a configurable builder object that prints the source code text of a
compilation unit, or a part of it, with emphasized fragments annotated with
custom messages.</p>
<pre><code class="language-text">   ╭──╢ Unit(1) ╟──────────────────────────────────────────────────────────────╮
 1 │ {                                                                         │
 2 │     "foo": true,                                                          │
 3 │     "bar": [123 "baz"]                                                    │
   │                ╰╴ missing ',' in Array                                    │
 4 │ }                                                                         │
   ├───────────────────────────────────────────────────────────────────────────┤
   │ Array syntax error.                                                       │
   ╰───────────────────────────────────────────────────────────────────────────╯
</code></pre>
<p>You create the builder in the Display or Debug context, providing the Document
(or any similar object with lexis, such as TokenBuffer) that needs to be
printed, and annotate arbitrary code spans with string messages.</p>
<p>Once building is finished, the Snippet prints the annotated snippet into the
Formatter's output.</p>
<p>The <a href="https://github.com/Eliah-Lakhin/lady-deirdre/blob/f350aaed30373a67694c3aba4d2cfd9874c2a656/work/crates/examples/src/json_highlight/highlighter.rs#L45">Json Highlight</a>
example demonstrates how to set up this builder on a custom object that wraps a
compilation unit document.</p>
<pre><code class="language-rust noplayground">pub struct JsonSnippet&lt;'a&gt; {
    pub doc: &amp;'a Document&lt;JsonNode&gt;,
    pub annotation: Vec&lt;(PositionSpan, AnnotationPriority, &amp;'static str)&gt;,
}

impl&lt;'a&gt; Display for JsonSnippet&lt;'a&gt; {
    fn fmt(&amp;self, formatter: &amp;mut Formatter&lt;'_&gt;) -&gt; std::fmt::Result {
        // You create the Snippet builder by calling the snippet function on
        // the Formatter. The specified parameter is a reference to the document
        // that contains the source code text.
        let mut snippet = formatter.snippet(self.doc);

        snippet
            // Configure the Snippet's header and footer text.
            // If omitted, the header and footer decorations will also be
            // omitted accordingly.
            .set_caption("Header text")
            .set_summary("Footer text.")
            // Specifies the highlighter that instructs the Snippet on how to
            // stylize individual tokens of the printed text.
            
            // This configuration is optional. When omitted, the Snippet will
            // print all tokens uniformly using the default color scheme.
            .set_highlighter(JsonHighlighter);

        for (span, priority, message) in &amp;self.annotation {
            // Adds an annotated span to the builder.
            //
            // The Snippet will print the specified fragment with an inverted
            // foreground (using the foreground color specified by
            // the annotation priority).
            //
            // If a message is present (the message string is not empty),
            // the Snippet will print this message near the spanned fragment.
            //
            // If the Snippet has specified annotations, it will print only
            // the source code lines that contain annotated fragments
            // (regardless of whether they have a message), plus some lines that
            // surround these lines before and after.
            //
            // If the Snippet does not have any annotations, it will print
            // the entire source code text.
            snippet.annotate(span, *priority, *message);
        }

        // Finishes the builder and prints the snippet to the Formatter's output.
        snippet.finish()
    }
}</code></pre>
<p>The Snippet has several drawing configuration options that you can specify using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.Snippet.html#method.set_config">Snippet::set_config</a>
function. Here are a few:</p>
<ul>
<li>You can show or hide line numbers, header and footer, and the outer frame.</li>
<li>You can enforce the Snippet to use ASCII-only drawing.</li>
<li>You can disable all terminal styles so that the Snippet will be monochrome.</li>
</ul>
<p>By default (if you don't provide the drawing config manually), the builder draws
the snippet with all drawing options turned off if the format is not
alternated (<code>format!("{}")</code>). Otherwise, all drawing options are
enabled (<code>format!("{:#}")</code>).</p>
<p>In the example above, we specify the JSON syntax highlighter using
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.Snippet.html#method.set_highlighter">Snippet::set_highlighter</a>
function.</p>
<p>The highlighter is a stateful object that implements
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/trait.Highlighter.html">Highlighter</a>
trait and instructs the Snippet on how to stylize the source code tokens. The
Snippet builder
calls <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/trait.Highlighter.html#tymethod.token_style">Highlighter::token_style</a>
for each token in the source code sequentially, and the function returns
the <a href="https://docs.rs/lady-deirdre/2.2.0/lady_deirdre/format/struct.Style.html">Style</a>
of the token.</p>
<pre><code class="language-rust noplayground">pub struct JsonHighlighter;

impl Highlighter&lt;JsonToken&gt; for JsonHighlighter {
    // The `dim` argument is set to true if this token is meant to have lesser
    // contrast than usual.
    //
    // The Snippet prefers to print the tokens outside of the annotated
    // fragments with lesser contrast to focus the user's attention on
    // the annotated spans.
    //
    // If the function returns None, it means that the token will be printed
    // without additional styles.
    fn token_style(&amp;mut self, dim: bool, token: JsonToken) -&gt; Option&lt;Style&gt; {
        match token {
            JsonToken::True | JsonToken::False | JsonToken::Null =&gt; Some(match dim {
                false =&gt; Style::new().blue(),
                true =&gt; Style::new().bright_blue(),
            }),

            JsonToken::String =&gt; Some(match dim {
                false =&gt; Style::new().green(),
                true =&gt; Style::new().bright_green(),
            }),

            JsonToken::BraceOpen | JsonToken::BraceClose =&gt; Some(Style::new().bold()),

            _ =&gt; None,
        }
    }
}</code></pre>
<p>Since the highlighter is a stateful object, it can rely on previous tokens to
make a decision about the next token style. For example, if the highlighter
discovers that the token is part of a comment or a string literal context, it
can stylize this token accordingly.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
